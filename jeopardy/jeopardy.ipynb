{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a87700e2",
   "metadata": {
    "id": "a87700e2"
   },
   "source": [
    "<!--<badge>--><a href=\"https://colab.research.google.com/github/startakovsky/pinecone-examples-fork/blob/master/jeopardy/jeopardy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a><!--</badge>-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df24e16b",
   "metadata": {
    "id": "df24e16b"
   },
   "source": [
    "# Do-it-yourself Jeopardy Board Curation with Pinecone\n",
    "\n",
    "<table><tr>\n",
    "<td> <img src=\"https://d33wubrfki0l68.cloudfront.net/682006698903a55560c796b901fdfe4446c6d27a/a00ee/images/pinecone-logo.svg\" alt=\"Pinecone\" style=\"width: 1000px;\"/> </td>\n",
    "<td> <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/5/51/Jeopardy%21_game_board_US.svg/2880px-Jeopardy%21_game_board_US.svg.png\" alt=\"Jeopardy Image\" style=\"width: 1000px;\"/> </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8253e2",
   "metadata": {
    "id": "ba8253e2"
   },
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8010267d",
   "metadata": {
    "id": "8010267d"
   },
   "source": [
    "### What is Semantic Search and how will we use it to play Jeopardy?\n",
    "\n",
    "We are going to use Pinecone's semantic search capabilities with an off-the-shelf and a pretrained model to curate custom categories of previously-aired Jeopardy questions. We will also show how Pinecone makes it easy to ensure that question difficulty is on par with how the question was originally priced.\n",
    "\n",
    "_Semantic search_ is exactly the kind of search where the _meaning_ of the search query is the thing that's used, rather than it being done by keyword lookups. Neural networks trained on large sets of text data have been shown to be very effective at encoding the _meaning_ of a particular phrase, sentence, paragraph or long document into a data structure known as a [vector embedding](https://www.pinecone.io/learn/vector-embeddings/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a228d497",
   "metadata": {
    "id": "a228d497"
   },
   "source": [
    "### Learning Goals and Estimated Reading Time\n",
    "_By the end of this 10 minute demo, you will have:_\n",
    " 1. Learned about Pinecone's value for solving realtime semantic search requirements!\n",
    " 2. Stored and retrieved vectors from Pinecone your very-own Pinecone Vector Database.\n",
    " 3. Encoded Jeopardy Questions as 384-dimensional vectors using a pretrained, encoder-only, model (i.e. no model training necessary).\n",
    " 4. Queried Pinecone's Vector Database on Jeopardy Questions that are semantically similar to the query.\n",
    " 5. Bonus for the Interested Reader: Near-Instant Custom Jeopardy Board Creation With Increasing Question Difficulty!\n",
    " \n",
    " If you want to execute the code yourself either in Google Colab or your computer, it may take up to an hour depending on processing speed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a99b115",
   "metadata": {
    "id": "1a99b115"
   },
   "source": [
    "## Setup: Prerequisites and Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60687f1",
   "metadata": {
    "id": "b60687f1"
   },
   "source": [
    "### Python 3.7+\n",
    "\n",
    "This code has been tested with Python 3.7. It is recommended to run this code in a virtual environment or Google Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6660547f",
   "metadata": {
    "id": "6660547f"
   },
   "source": [
    "### Acquiring your Pinecone API Key\n",
    "\n",
    "A Pinecone API key is required. You can obtain one for free on our [our website](https://app.pinecone.io/). Either add `PINECONE_EXAMPLE_API_KEY` to your list of environmental variables, or manually enter it after running the below cell (a prompt will pop up requesting the API key, storing the result within this kernel (session))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edfb9e5",
   "metadata": {
    "id": "7edfb9e5"
   },
   "source": [
    "### Installing and Importing Prerequisite Libraries:\n",
    "Common Python libraries, including [pinecone-client](https://pypi.org/project/pinecone-client/) and [sentence_transformers](https://pypi.org/project/sentence-transformers/) are required for this notebook. They will be installed in the next cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a12400a",
   "metadata": {
    "id": "3a12400a"
   },
   "source": [
    "#### Installing via `pip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a1fa96d",
   "metadata": {
    "id": "8a1fa96d"
   },
   "outputs": [],
   "source": [
    "!pip install pinecone-client sentence-transformers datasets pandas tqdm httpimport -qU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3b5752",
   "metadata": {
    "id": "fc3b5752"
   },
   "source": [
    "### Helper Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96cb344b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "id": "96cb344b",
    "outputId": "5a3daf3d-6d1a-46fb-8a21-2140cf6266c2"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Extracting API Key from environmental variable `PINECONE_EXAMPLE_API_KEY`..."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Pinecone API Key available at `h.pinecone_api_key`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# There is a helper module required for this notebook to run.\n",
    "# When not present with this notebook, it will be streamed in from Pinecone's Example Repository.\n",
    "# You can find the module at https://github.com/pinecone-io/examples/tree/master/jeopardy\n",
    "\n",
    "import os\n",
    "import httpimport\n",
    "\n",
    "if os.path.isfile('helper.py'):\n",
    "    import helper as h\n",
    "else:\n",
    "    print('importing `helper.py` from https://github.com/pinecone-io')\n",
    "    with httpimport.github_repo(\n",
    "        username='pinecone-io', \n",
    "        repo='examples',\n",
    "        module=['jeopardy'],\n",
    "        branch='master'):\n",
    "        from jeopardy import helper as h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9441c1df",
   "metadata": {
    "id": "9441c1df"
   },
   "source": [
    "#### Importing and Defining Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7281780",
   "metadata": {
    "id": "c7281780"
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "import tqdm\n",
    "import pinecone\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from datasets import load_dataset\n",
    "\n",
    "INDEX_NAME, INDEX_DIMENSION = 'jeopardy', 384\n",
    "MODEL_NAME = 'sentence-transformers/msmarco-MiniLM-L6-cos-v5'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfefda6",
   "metadata": {
    "id": "0cfefda6"
   },
   "source": [
    "### Downloading and Processing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddb4ccc",
   "metadata": {
    "id": "0ddb4ccc"
   },
   "source": [
    "#### Downloading data\n",
    "The [Jeopardy Dataset](https://huggingface.co/datasets/jeopardy) will be downloaded using the `datasets` library from HuggingFace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f325264a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f325264a",
    "outputId": "54776135-3862-49a9-d0e5-b5c1a0364749"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset jeopardy (/Users/steven/.cache/huggingface/datasets/jeopardy/default/0.1.0/774efb3257b2f482b1974faa754e6ce11853ad625a9b364e29f106052afe0204)\n"
     ]
    }
   ],
   "source": [
    "rows = 20_000  # increase/decrease this to use more/less data, or\n",
    "# remove the `split` keyword argument to get the entire dataset (has a little over 200,000 rows)\n",
    "# Using the entire dataset will take longer to get through this demo, and not recommended as a first pass\n",
    "\n",
    "dataset = load_dataset(\"jeopardy\", split=f\"train[130000:{130_000+rows}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f916fa",
   "metadata": {
    "id": "35f916fa"
   },
   "source": [
    "#### The preprocessing step is self-explanatory and defined in the helper module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "919c98fe",
   "metadata": {
    "id": "919c98fe"
   },
   "outputs": [],
   "source": [
    "df = dataset.to_pandas()\n",
    "df = h.get_processed_df(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc22766",
   "metadata": {
    "id": "4dc22766"
   },
   "source": [
    "#### Sample row from dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fff4d03e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362
    },
    "id": "fff4d03e",
    "outputId": "3ad96df8-70f8-4051-d252-7dfd8c858f83"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1443</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <td>NAME THAT NOVEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>air_date</th>\n",
       "      <td>1997-09-04 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question</th>\n",
       "      <td>'\"'What a pretty little Nell!' cried Quilp.\"'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amount</th>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer</th>\n",
       "      <td>The Old Curiosity Shop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>round</th>\n",
       "      <td>Double Jeopardy!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>show_number</th>\n",
       "      <td>2989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <td>09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_to_encode</th>\n",
       "      <td>'\"'What a pretty little Nell!' cried Quilp.\"' The Old Curiosity Shop</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                1443\n",
       "category                                                             NAME THAT NOVEL\n",
       "air_date                                                         1997-09-04 00:00:00\n",
       "question                               '\"'What a pretty little Nell!' cried Quilp.\"'\n",
       "amount                                                                          1000\n",
       "answer                                                        The Old Curiosity Shop\n",
       "round                                                               Double Jeopardy!\n",
       "show_number                                                                     2989\n",
       "year                                                                            1997\n",
       "month                                                                             09\n",
       "text_to_encode  '\"'What a pretty little Nell!' cried Quilp.\"' The Old Curiosity Shop"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df.iloc[1234])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e57c70f",
   "metadata": {
    "id": "3e57c70f"
   },
   "source": [
    "### Creating your Pinecone Index\n",
    "The process for creating a Pinecone Index requires your Pinecone API key, the name of your index, and the number of dimensions of each vector. As we will see below, the model we are using maps each piece of text to a 384-dimensional vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d03750c",
   "metadata": {
    "id": "7d03750c"
   },
   "outputs": [],
   "source": [
    "pinecone.init(api_key=h.pinecone_api_key, environment='us-west1-gcp')\n",
    "\n",
    "if INDEX_NAME not in pinecone.list_indexes():\n",
    "    pinecone.create_index(name=INDEX_NAME, dimension=INDEX_DIMENSION)\n",
    "\n",
    "index = pinecone.Index(index_name=INDEX_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546f0219",
   "metadata": {
    "id": "546f0219"
   },
   "source": [
    "## Generate embeddings and send them to your Pinecone Index\n",
    "This will all be done in batches. We will compute embeddings in batch, followed by taking each batch and sending it to Pinecone, also in batches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecbb5e8",
   "metadata": {
    "id": "9ecbb5e8"
   },
   "source": [
    "### Loading a Pretrained Encoder model.\n",
    "We will generate embeddings by using [this Sentence Transformers model](https://huggingface.co/sentence-transformers/msmarco-MiniLM-L6-cos-v5). It is one of hundreds of encoder models available. Downloads happen automatically with SentenceTransformer, and may take up to a minute the first time. After this first import, the model is cached and available on a local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4ed4a8c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "b4ed4a8c",
    "outputId": "1b20b519-9599-4b79-876c-a63f90324591"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Loading model from _Sentence Transformers_: `sentence-transformers/msmarco-MiniLM-L6-cos-v5` from Sentence Transformers..."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Model loaded."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h.printmd(f'Loading model from _Sentence Transformers_: `{MODEL_NAME}` from Sentence Transformers...')\n",
    "model = SentenceTransformer(MODEL_NAME)\n",
    "h.printmd('Model loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4d4005",
   "metadata": {
    "id": "fd4d4005"
   },
   "source": [
    "### MSMARCO model v5 and Embeddings\n",
    "\n",
    "In this example, we created an index with 384 dimensions because that is what the output is of this MSMARCO model. In fact, particular MSMARCO model used in this example generates [unit vectors](https://en.wikipedia.org/wiki/Unit_vector), which make [vector comparisons](https://towardsdatascience.com/importance-of-distance-metrics-in-machine-learning-modelling-e51395ffe60d) agnostic to one's choice of similarity scores. In other words, when defining the index, it does not matter whether we use `euclidean`, `cosine` or `dotproduct` as a metric, so we left it blank, using the `cosine` default. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a13a56",
   "metadata": {
    "id": "25a13a56"
   },
   "source": [
    "#### On Embeddings\n",
    "\n",
    "The output of this model's encodings are 384-dimensional, which was known in advance of creating above index.\n",
    "\n",
    "So, when a piece of text such as \"A quick fox jumped around\" gets encoded into a vector embedding, the result is a sequence of floats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb16d277",
   "metadata": {
    "id": "bb16d277"
   },
   "source": [
    "#### On Comparing Embeddings aka _how_ Semantic Search works\n",
    "\n",
    "Two 15-dimensional text embeddings might look like something like: \n",
    " - _\\[-0.02, 0.06, 0.0, 0.01, 0.08, -0.03, 0.01, 0.02, 0.01, 0.02, -0.07, -0.11, -0.01, 0.08, -0.04\\]_\n",
    " - _\\[-0.04, -0.09, 0.04, -0.1, -0.05, -0.01, -0.06, -0.04, -0.02, -0.04, -0.04, 0.07, 0.03, 0.02, 0.03\\]_\n",
    " \n",
    "In order to determine how _similar_ we may use something like [cosine distance](https://en.wikipedia.org/wiki/Cosine_similarity). This calculation is trivial when comparing two vectors, but nontrivial when needing to compare one vector against millions or billions of vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d71e442",
   "metadata": {
    "id": "3d71e442"
   },
   "source": [
    "### What is Pinecone for?\n",
    "Often, there is a technical requirement to run a comparison of one vector to millions of others and return the most similar results in real time, with a latency of tens of milliseconds and at a high throughput. Pinecone solves this  problem with its managed vector database service, and we will demonstrate this below. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46933021",
   "metadata": {
    "id": "46933021"
   },
   "source": [
    "### Prepare vector embeddings for upload\n",
    "\n",
    "This may take a while depending on your machine. If on a recent MacBookPro or Google Colab, this may take up to one hour, sometimes longer.\n",
    "\n",
    "#### Prepare metadata\n",
    "\n",
    "The function below creates metadata from a single row of the dataframe. This is going to be important further down this notebook for additional filter requirements we will may want to employ in our queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "330d389c",
   "metadata": {
    "id": "330d389c"
   },
   "outputs": [],
   "source": [
    "def get_vector_metadata_from_dataframe_row(df_row):\n",
    "    \"\"\"Return pinecone vector.\"\"\"\n",
    "    vector_metadata = {\n",
    "        'year': df_row['year'],\n",
    "        'month': df_row['month'],\n",
    "        'round': df_row['round'],\n",
    "        'amount': df_row['amount']\n",
    "    }\n",
    "    return vector_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1e0478",
   "metadata": {
    "id": "0c1e0478"
   },
   "source": [
    "#### Prepare all vector data for upload\n",
    "\n",
    "The function below will take a portion of the dataframe and create the full vector data as Pinecone expects it for [upsert](https://www.pinecone.io/docs/insert-data/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40c3862c",
   "metadata": {
    "id": "40c3862c"
   },
   "outputs": [],
   "source": [
    "def get_vectors_to_upload_to_pinecone(df_chunk, model):\n",
    "    \"\"\"Return list of tuples like (vector_id, vector_values, vector_metadata).\"\"\"\n",
    "    # create embeddings\n",
    "    pool = model.start_multi_process_pool()\n",
    "    vector_values = model.encode_multi_process(df_chunk['text_to_encode'], pool).tolist()\n",
    "    model.stop_multi_process_pool(pool)\n",
    "    # create vector ids and metadata\n",
    "    vector_ids = df_chunk.index.tolist()\n",
    "    vector_metadata = df_chunk.apply(get_vector_metadata_from_dataframe_row,axis=1).tolist()\n",
    "    return list(zip(vector_ids, vector_values, vector_metadata))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040cc6d7",
   "metadata": {
    "id": "040cc6d7"
   },
   "source": [
    "### Upload data to Pinecone in asynchronous batches\n",
    "\n",
    "The function below iterates through the dataframe in chunks, and for each of those chunks, will upload asynchronously in sub-chunks to your Pinecone Index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "256e593c",
   "metadata": {
    "id": "256e593c"
   },
   "outputs": [],
   "source": [
    "def upload_dataframe_to_pinecone_in_chunks(\n",
    "    dataframe, \n",
    "    pinecone_index, \n",
    "    model, \n",
    "    chunk_size=20000, \n",
    "    upsert_size=100):\n",
    "    \"\"\"Encode dataframe column `text_to_encode` to dense vector and upsert to Pinecone.\"\"\"\n",
    "    tqdm_kwargs = h.get_tqdm_kwargs(dataframe, chunk_size)\n",
    "    async_results = collections.defaultdict(list)\n",
    "    for df_chunk in tqdm.notebook.tqdm(h.chunks(dataframe, chunk_size), **tqdm_kwargs):\n",
    "        vectors = get_vectors_to_upload_to_pinecone(df_chunk, model)\n",
    "        # upload to Pinecone in batches of `upsert_size`\n",
    "        for vectors_chunk in h.chunks(vectors, upsert_size):\n",
    "            start_index_chunk = df_chunk.index[0]\n",
    "            async_result = pinecone_index.upsert(vectors_chunk, async_req=True)\n",
    "            async_results[start_index_chunk].append(async_result)\n",
    "        # wait for results\n",
    "        _ = [async_result.get() for async_result in async_results[start_index_chunk]]\n",
    "        is_all_successful = all(map(lambda x: x.successful(), async_results[start_index_chunk]))\n",
    "        # report chunk upload status\n",
    "        print(\n",
    "        f'All upserts in chunk successful with index starting with {start_index_chunk:>7}: '\n",
    "        f'{is_all_successful}. Vectors uploaded: {len(vectors):>3}.'\n",
    "        )\n",
    "    return async_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091ef5c8",
   "metadata": {
    "id": "091ef5c8"
   },
   "source": [
    "#### Asynchronous Upload\n",
    "Computing the embeddings may take up to a couple of minutes per 20k vector chunk depending on hardware capabilities. Once computed it will be nearly instantaneous to send the embeddings to Pinecone. The Pinecone API responds right away with its [async](https://www.pinecone.io/docs/insert-data/#sending-upserts-in-parallel) requests. \n",
    "\n",
    "Note: You may see the following output a few times when executing, it is not an error: \n",
    "```\n",
    "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
    "To disable this warning, you can either:\n",
    "\t- Avoid using `tokenizers` before the fork if possible\n",
    "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ba75643",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "7234d04b9de94d7e98ce01a0fbe5c421",
      "db8a1a3bf026432db24d0ea253f7dd87",
      "b45a50c5e2b54934b17750d9453ce6dd",
      "fd32d1f08d5a423294b5d584dc991d31",
      "e80326902e724ff28335112a88ddb587",
      "a410d79870cd4e24a4e4bdeffe6c7ae9",
      "dabd3820ac70497b8af3f6eaba30dd76",
      "f6bbd18c5606487eac25577aa8e996eb",
      "e5151e91dfec48939ea421a2ba8435af",
      "794641c9927048ae9b82af8e676c6750",
      "eaa036f5881647b0b4392e9ebe2d396f"
     ]
    },
    "id": "5ba75643",
    "outputId": "3f98f865-206e-48a6-f600-e538c4b8d742",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "153fd5c0520d48aebbb7101ddf4b6c8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?chunk of vectors/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All upserts in chunk successful with index starting with       0: True. Vectors uploaded: 16917.\n"
     ]
    }
   ],
   "source": [
    "async_results = upload_dataframe_to_pinecone_in_chunks(df, index, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eddac13",
   "metadata": {
    "id": "0eddac13"
   },
   "source": [
    "### Visualize the status of your upserts in the Pinecone Console\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/startakovsky/pinecone-examples-fork/jeopardy/jeopardy/pinecone_console.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f6de60",
   "metadata": {
    "id": "d2f6de60"
   },
   "source": [
    "## Querying Pinecone\n",
    "\n",
    "Now that all the embeddings of the texts are on Pinecone's database, it's time to demonstrate Pinecone's lightning fast semantic search query capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e5033f",
   "metadata": {
    "id": "a8e5033f"
   },
   "source": [
    "### Pinecone Example Usage\n",
    "\n",
    "#### _**Show me Jeopardy questions that are semantically similar to \"ancient attitudes\"\\!**_\n",
    "\n",
    "In the below example we query Pinecone's API with an embedding of a query term to return the vector embeddings that have the highest similarity score. In other words, Pinecone does all the work to effeciently determine which of the uploaded vector embeddings have the highest similarity when paired with the query term's embedding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c62f6d",
   "metadata": {
    "id": "d6c62f6d"
   },
   "source": [
    "#### Example: Pinecone API Request\n",
    "\n",
    "A sample request for questions that that a similar semantic meaning to _ancient attitudes_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53f6d28f",
   "metadata": {
    "id": "53f6d28f"
   },
   "outputs": [],
   "source": [
    "query = 'ancient attitudes'\n",
    "vector_embedding = model.encode(query).tolist()\n",
    "response = index.query([vector_embedding], top_k=3, include_metadata=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3460d6f6",
   "metadata": {
    "id": "3460d6f6"
   },
   "source": [
    "#### Pinecone API Response\n",
    "A typical Pinecone response to the above query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0947f60",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 433
    },
    "id": "a0947f60",
    "outputId": "4bae44cf-c846-4730-c71b-bb21f06a588e"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "{'matches': [],\n",
       " 'namespace': '',\n",
       " 'results': [{'matches': [{'id': '1253',\n",
       "                           'metadata': {'amount': 1200.0,\n",
       "                                        'month': '01',\n",
       "                                        'round': 'Double Jeopardy!',\n",
       "                                        'year': '2006'},\n",
       "                           'score': 0.510472894,\n",
       "                           'values': []},\n",
       "                          {'id': '18032',\n",
       "                           'metadata': {'amount': 400.0,\n",
       "                                        'month': '11',\n",
       "                                        'round': 'Double Jeopardy!',\n",
       "                                        'year': '1991'},\n",
       "                           'score': 0.39200142,\n",
       "                           'values': []},\n",
       "                          {'id': '9436',\n",
       "                           'metadata': {'amount': 1000.0,\n",
       "                                        'month': '06',\n",
       "                                        'round': 'Jeopardy!',\n",
       "                                        'year': '2011'},\n",
       "                           'score': 0.389683,\n",
       "                           'values': []}],\n",
       "              'namespace': ''}]}\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# A hacky way to print the response object in color.\n",
    "h.printmd(f\"```python\\n{response}\\n```\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c93ba5f",
   "metadata": {
    "id": "1c93ba5f"
   },
   "source": [
    "#### Enriched Response\n",
    "To show which questions we retreived, the above response needs to be enriched using the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a35cff62",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 174
    },
    "id": "a35cff62",
    "outputId": "f1826ca1-9bb1-4d21-cece-1c6599ba42f3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>amount</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vector_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>'Modern cultural movement emphasizing alternative approaches to spirituality'</td>\n",
       "      <td>New Age</td>\n",
       "      <td>1200</td>\n",
       "      <td>ancient attitudes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18032</th>\n",
       "      <td>'These historical epics which the Vikings learned by heart were passed on from generation to generation'</td>\n",
       "      <td>Sagas/eddas</td>\n",
       "      <td>400</td>\n",
       "      <td>ancient attitudes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9436</th>\n",
       "      <td>'This \"elder\" Roman writer died in 79 A.D. while rescuing people from mount Vesuvius' eruption'</td>\n",
       "      <td>Pliny (the Elder)</td>\n",
       "      <td>1000</td>\n",
       "      <td>ancient attitudes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                           question  \\\n",
       "vector_id                                                                                                             \n",
       "1253                                  'Modern cultural movement emphasizing alternative approaches to spirituality'   \n",
       "18032      'These historical epics which the Vikings learned by heart were passed on from generation to generation'   \n",
       "9436                'This \"elder\" Roman writer died in 79 A.D. while rescuing people from mount Vesuvius' eruption'   \n",
       "\n",
       "                      answer  amount              query  \n",
       "vector_id                                                \n",
       "1253                 New Age    1200  ancient attitudes  \n",
       "18032            Sagas/eddas     400  ancient attitudes  \n",
       "9436       Pliny (the Elder)    1000  ancient attitudes  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.get_query_results_from_api_response(df, response, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3108f73",
   "metadata": {
    "id": "b3108f73"
   },
   "source": [
    "### Pinecone Example Usage With [Metadata](https://www.pinecone.io/docs/metadata-filtering/)\n",
    "\n",
    "Some of the above do turn out to be related to _ancient attidues_, which is pretty spectacular! _Note that this is **not a keyword search** but rather a **search for semantically similar results**.\n",
    "\n",
    "But we can do better! In Jeopardy, you choose a question **and** a price point, where, in general, higher prices indicate harder questions. So it is natural to want to choose semantically similar questions from a specific price point.\n",
    "\n",
    "#### _Can I see 5 questions related to \"ancient attitudes\" for \\$1000?_\n",
    "\n",
    "Yes. Pinecone's [metadata feature](https://www.pinecone.io/docs/metadata-filtering/) makes this request trivial. We've already uploaded the metadata so filtering is just a Pinecone API request away. The only difference we make to the api request is to add the `filter_criteria` keyword argument like so: \n",
    "\n",
    "```python\n",
    "index.query([vector_embedding], top_k=5, include_metadata=True, filter_criteria={'amount': {'$eq': 1000}})\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd61f365",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "bd61f365",
    "outputId": "d7fb9c6c-ac7f-4e7c-f5b2-504ebd163450"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>amount</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vector_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9436</th>\n",
       "      <td>'This \"elder\" Roman writer died in 79 A.D. while rescuing people from mount Vesuvius' eruption'</td>\n",
       "      <td>Pliny (the Elder)</td>\n",
       "      <td>1000</td>\n",
       "      <td>ancient attitudes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11124</th>\n",
       "      <td>'The most famous one of these shrines in the ancient world was located on the slopes of Mount Parnassus'</td>\n",
       "      <td>Oracle</td>\n",
       "      <td>1000</td>\n",
       "      <td>ancient attitudes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3737</th>\n",
       "      <td>'Books 12-19 of this \"elder\" ancient Roman's \"Natural History\" are devoted to botany'</td>\n",
       "      <td>Pliny the Elder</td>\n",
       "      <td>1000</td>\n",
       "      <td>ancient attitudes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19547</th>\n",
       "      <td>'In the old Hindu caste system the twice-born castes were the Vaisyas, the Kshatriyas &amp; this, which included priests'</td>\n",
       "      <td>Brahmins</td>\n",
       "      <td>1000</td>\n",
       "      <td>ancient attitudes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>'We took the word nirvana from this classical language'</td>\n",
       "      <td>Sanskrit</td>\n",
       "      <td>1000</td>\n",
       "      <td>ancient attitudes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                        question  \\\n",
       "vector_id                                                                                                                          \n",
       "9436                             'This \"elder\" Roman writer died in 79 A.D. while rescuing people from mount Vesuvius' eruption'   \n",
       "11124                   'The most famous one of these shrines in the ancient world was located on the slopes of Mount Parnassus'   \n",
       "3737                                       'Books 12-19 of this \"elder\" ancient Roman's \"Natural History\" are devoted to botany'   \n",
       "19547      'In the old Hindu caste system the twice-born castes were the Vaisyas, the Kshatriyas & this, which included priests'   \n",
       "520                                                                      'We took the word nirvana from this classical language'   \n",
       "\n",
       "                      answer  amount              query  \n",
       "vector_id                                                \n",
       "9436       Pliny (the Elder)    1000  ancient attitudes  \n",
       "11124                 Oracle    1000  ancient attitudes  \n",
       "3737         Pliny the Elder    1000  ancient attitudes  \n",
       "19547               Brahmins    1000  ancient attitudes  \n",
       "520                 Sanskrit    1000  ancient attitudes  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.get_query_results_from_query(query, index, df, model, top_k=5, filter_criteria={'amount': {'$eq': 1000}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b2fdb6",
   "metadata": {
    "id": "41b2fdb6"
   },
   "source": [
    "Pretty good, right? Every question above is from the dataset, each one of them previously aired on Jeopardy for \\$1000, and, while subjective, most of them have to do with _antient attidues_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2442b3",
   "metadata": {
    "id": "2b2442b3"
   },
   "source": [
    "### An Additional Note on Metadata\n",
    "\n",
    "This is a basic demonstration of metadata. Extensive predicate logic can be applied to metadata filtering, just like the [WHERE clause](https://www.pinecone.io/learn/vector-search-filtering/) in SQL!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a42e36",
   "metadata": {
    "id": "d3a42e36"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we demonstrated how trivial Pinecone makes instant retrieval of similar vector embeddings to create custom Jeopardy questions of a pre-assigned difficulty. We did not need to train any models or develop any algorithms to allow for this type of instant computation. This example is illustrative of how to use a pre-trained transformer-encoder model with Pinecone to achieve realtime similarity retrieval!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fed76d",
   "metadata": {
    "id": "d5fed76d"
   },
   "source": [
    "### Like what you see? Explore our [community](https://www.pinecone.io/community/)\n",
    "Learn more about semantic search and the rich, performant, and production-level feature set of Pinecone's Vector Database by visiting https://pinecone.io, connect with us [here](https://www.pinecone.io/contact/) and [follow us](https://www.linkedin.com/company/pinecone-io) on LinkedIn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a8f76c",
   "metadata": {
    "id": "41a8f76c"
   },
   "source": [
    "## Bonus Material: Jeopardy Building Custom Jeopardy Boards\n",
    "\n",
    "For the interested reader, we've created a few functions in the helper module that will automatically generate Jeopardy Boards. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553130a4",
   "metadata": {
    "id": "553130a4"
   },
   "source": [
    "### Pinecone Query for All Question Difficulties\n",
    "Now, we scale up the previous example and wrangle the output into the form of two Jeopardy Boards (First and second round)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4480cf1b",
   "metadata": {
    "id": "4480cf1b"
   },
   "source": [
    "### Jeopardy! Round 1 Board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "860e5675",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437
    },
    "id": "860e5675",
    "outputId": "1bc5198f-d608-430c-b708-4e1e2b824603",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>over the moon</th>\n",
       "      <th>ancient atitudes</th>\n",
       "      <th>invention of computer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amount</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>'It's the colossal booster rocket that lifted the Apollo missions to the moon'</td>\n",
       "      <td>'In 1909 Dutch botanist Wilhelm Johannsen first proposed this name for the unit of heredity in living things'</td>\n",
       "      <td>'The World Almanac's list of inventions runs from Pascal's adding machine to this fastener by Judson'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>'The casino named for this heavenly body will feature the scintillating lounge act of Neil Armstrong &amp; Buzz Aldrin'</td>\n",
       "      <td>'These historical epics which the Vikings learned by heart were passed on from generation to generation'</td>\n",
       "      <td>'Around 132 A.D. Chinese scientist Chang Heng invented an early form of this earthquake detector'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>'In June 1978 the first moon to be discovered around this planet was found by James W. Christy'</td>\n",
       "      <td>'As a boy in ancient China, this sage was known as Ch'iu, meaning \"hill\", because of his protuberant forehead'</td>\n",
       "      <td>'For 16 years this computer maker put an ad on the back page of PC Mag to promote &amp; pioneer its direct PC sales'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>'Earth's natural satellite between May &amp; July'</td>\n",
       "      <td>'In \"The Village Blacksmith\", Longfellow wrote of this \"Sounding\" object that the Blacksmith's hammer strikes'</td>\n",
       "      <td>'Yankee profiled \"New England's greatest invention\"--this one created in a restaurant on a Mass. toll road'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>'\"Fly Me to the Moon\" is Volume V in the \"Great American Songbook\" series by this British rocker'</td>\n",
       "      <td>'According to Proverbs, \"He that troubleth his own house shall\" do this'</td>\n",
       "      <td>'In 1821, he became only person to invent, unaided, an entire alphabet &amp; numbering system'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                              over the moon  \\\n",
       "amount                                                                                                                        \n",
       "200                                          'It's the colossal booster rocket that lifted the Apollo missions to the moon'   \n",
       "400     'The casino named for this heavenly body will feature the scintillating lounge act of Neil Armstrong & Buzz Aldrin'   \n",
       "600                         'In June 1978 the first moon to be discovered around this planet was found by James W. Christy'   \n",
       "800                                                                          'Earth's natural satellite between May & July'   \n",
       "1000                      '\"Fly Me to the Moon\" is Volume V in the \"Great American Songbook\" series by this British rocker'   \n",
       "\n",
       "                                                                                                      ancient atitudes  \\\n",
       "amount                                                                                                                   \n",
       "200      'In 1909 Dutch botanist Wilhelm Johannsen first proposed this name for the unit of heredity in living things'   \n",
       "400           'These historical epics which the Vikings learned by heart were passed on from generation to generation'   \n",
       "600     'As a boy in ancient China, this sage was known as Ch'iu, meaning \"hill\", because of his protuberant forehead'   \n",
       "800     'In \"The Village Blacksmith\", Longfellow wrote of this \"Sounding\" object that the Blacksmith's hammer strikes'   \n",
       "1000                                          'According to Proverbs, \"He that troubleth his own house shall\" do this'   \n",
       "\n",
       "                                                                                                   invention of computer  \n",
       "amount                                                                                                                    \n",
       "200                'The World Almanac's list of inventions runs from Pascal's adding machine to this fastener by Judson'  \n",
       "400                    'Around 132 A.D. Chinese scientist Chang Heng invented an early form of this earthquake detector'  \n",
       "600     'For 16 years this computer maker put an ad on the back page of PC Mag to promote & pioneer its direct PC sales'  \n",
       "800          'Yankee profiled \"New England's greatest invention\"--this one created in a restaurant on a Mass. toll road'  \n",
       "1000                          'In 1821, he became only person to invent, unaided, an entire alphabet & numbering system'  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries = [\"over the moon\", \"ancient atitudes\", \"invention of computer\"]\n",
    "jeopardy_questions = h.get_jeopardy_questions(queries, index, df, model)\n",
    "jeopardy_board, double_jeopardy_board = h.get_jeopardy_boards(jeopardy_questions, queries)\n",
    "jeopardy_board"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc40f4d1",
   "metadata": {
    "id": "bc40f4d1"
   },
   "source": [
    "### Double Jeopardy! Round 2 Board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1877d59a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 368
    },
    "id": "1877d59a",
    "outputId": "430f2662-3c49-4790-b305-e664d6eef053"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>over the moon</th>\n",
       "      <th>ancient atitudes</th>\n",
       "      <th>invention of computer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amount</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>'High-aiming standard heard here'</td>\n",
       "      <td>'2 ways of gaining knowledge described by Kant were \"a posteriori\" &amp; this Latin opposite'</td>\n",
       "      <td>'Invention (proverbially)'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1400</th>\n",
       "      <td>'One of these long-lived animals that died in 1966 was reportedly given to the King of Tonga by Captain Cook'</td>\n",
       "      <td>'In the 1770s this archduchess of Austria pioneered a national system of elementary education'</td>\n",
       "      <td>'In the 1770s this archduchess of Austria pioneered a national system of elementary education'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>'Shine on if you see this closest full moon to the fall equinox'</td>\n",
       "      <td>'Rowena has Saxon the brain in this 1819 work by Sir Walter Scott'</td>\n",
       "      <td>'...who conjured up Shangri-La for a 1933 novel'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1800</th>\n",
       "      <td>'This technology used for wireless headsets is named after a Danish king who united parts of Scandinavia'</td>\n",
       "      <td>'Muslims believe that Abraham helped build this building in Mecca thousands of years ago'</td>\n",
       "      <td>'This technology used for wireless headsets is named after a Danish king who united parts of Scandinavia'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>'335 B.C.:&lt;br /&gt;This Greek philosopher uses lunar eclipses to prove the Earth is ball shaped'</td>\n",
       "      <td>'The major evidence that these people visited North America has been found at L'Anse aux Meadows'</td>\n",
       "      <td>'Ed Roberts built the first true personal computer &amp; named it this model 8800, after a star'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                        over the moon  \\\n",
       "amount                                                                                                                  \n",
       "1200                                                                                'High-aiming standard heard here'   \n",
       "1400    'One of these long-lived animals that died in 1966 was reportedly given to the King of Tonga by Captain Cook'   \n",
       "1600                                                 'Shine on if you see this closest full moon to the fall equinox'   \n",
       "1800        'This technology used for wireless headsets is named after a Danish king who united parts of Scandinavia'   \n",
       "2000                    '335 B.C.:<br />This Greek philosopher uses lunar eclipses to prove the Earth is ball shaped'   \n",
       "\n",
       "                                                                                         ancient atitudes  \\\n",
       "amount                                                                                                      \n",
       "1200            '2 ways of gaining knowledge described by Kant were \"a posteriori\" & this Latin opposite'   \n",
       "1400       'In the 1770s this archduchess of Austria pioneered a national system of elementary education'   \n",
       "1600                                   'Rowena has Saxon the brain in this 1819 work by Sir Walter Scott'   \n",
       "1800            'Muslims believe that Abraham helped build this building in Mecca thousands of years ago'   \n",
       "2000    'The major evidence that these people visited North America has been found at L'Anse aux Meadows'   \n",
       "\n",
       "                                                                                            invention of computer  \n",
       "amount                                                                                                             \n",
       "1200                                                                                   'Invention (proverbially)'  \n",
       "1400               'In the 1770s this archduchess of Austria pioneered a national system of elementary education'  \n",
       "1600                                                             '...who conjured up Shangri-La for a 1933 novel'  \n",
       "1800    'This technology used for wireless headsets is named after a Danish king who united parts of Scandinavia'  \n",
       "2000                 'Ed Roberts built the first true personal computer & named it this model 8800, after a star'  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "double_jeopardy_board"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb50b53e",
   "metadata": {
    "id": "bb50b53e"
   },
   "source": [
    "### Looking Up Answers!\n",
    "See if you can think of the answer to this question which you can view in the above jeopardy board: \n",
    "#### _Over the moon for 400 please, Alex!_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "603c7b1e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111,
     "referenced_widgets": [
      "cab86a69853e45cb897798015240a3ee",
      "5bf9dbf1847b4684b286b49856a275a2",
      "8715a090d1f042d186db3c302a4775a2",
      "929924cc164841a9bc3b68e7a90aa0e6",
      "06399d4790514835b9088c493c2eff96",
      "f9df21b9c0404dc0811fc923ebe4ef53",
      "f1a52b1d813e4bbeac7634dc622cf738",
      "2328339d8256480da2d5b1c8f51830c8",
      "7cee0e4dcae744708847c5549b69786a",
      "cfb956b5e6e54708b6897475c10bd01a",
      "c1cc500fe24a4538a81089e6c957a1f6"
     ]
    },
    "id": "603c7b1e",
    "outputId": "981218c6-9bc7-4c87-89e1-0ddc1bc88d80"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "430f792f1351436b908c7f613df19d88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='query:', options=('over the moon', 'ancient atitudes', 'invention of computer'), value='"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "835af7dce3494738849ba44a79f3badb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='amount:', options=(200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000), value=200)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1a74b86af964da7b79835bac04ef0ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Submit', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0af81028b4b64ecd8fcb68b4e4d815c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h.show_answer_widget(jeopardy_questions, queries)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "25a13a56",
    "bb16d277"
   ],
   "name": "jeopardy.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "38cca0c38332a56087b24af0bc80247f4fced29cb4f7f437d91dc159adec9c4e"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "06399d4790514835b9088c493c2eff96": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2328339d8256480da2d5b1c8f51830c8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5bf9dbf1847b4684b286b49856a275a2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7234d04b9de94d7e98ce01a0fbe5c421": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_db8a1a3bf026432db24d0ea253f7dd87",
       "IPY_MODEL_b45a50c5e2b54934b17750d9453ce6dd",
       "IPY_MODEL_fd32d1f08d5a423294b5d584dc991d31"
      ],
      "layout": "IPY_MODEL_e80326902e724ff28335112a88ddb587"
     }
    },
    "794641c9927048ae9b82af8e676c6750": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7cee0e4dcae744708847c5549b69786a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    },
    "8715a090d1f042d186db3c302a4775a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "929924cc164841a9bc3b68e7a90aa0e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DropdownModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DropdownModel",
      "_options_labels": [
       "200",
       "400",
       "600",
       "800",
       "1000",
       "1200",
       "1400",
       "1600",
       "1800",
       "2000"
      ],
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "DropdownView",
      "description": "amount:",
      "description_tooltip": null,
      "disabled": false,
      "index": 0,
      "layout": "IPY_MODEL_06399d4790514835b9088c493c2eff96",
      "style": "IPY_MODEL_f9df21b9c0404dc0811fc923ebe4ef53"
     }
    },
    "a410d79870cd4e24a4e4bdeffe6c7ae9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b45a50c5e2b54934b17750d9453ce6dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f6bbd18c5606487eac25577aa8e996eb",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e5151e91dfec48939ea421a2ba8435af",
      "value": 1
     }
    },
    "c1cc500fe24a4538a81089e6c957a1f6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cab86a69853e45cb897798015240a3ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DropdownModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DropdownModel",
      "_options_labels": [
       "over the moon",
       "ancient atitudes",
       "invention of computer"
      ],
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "DropdownView",
      "description": "query:",
      "description_tooltip": null,
      "disabled": false,
      "index": 0,
      "layout": "IPY_MODEL_5bf9dbf1847b4684b286b49856a275a2",
      "style": "IPY_MODEL_8715a090d1f042d186db3c302a4775a2"
     }
    },
    "cfb956b5e6e54708b6897475c10bd01a": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_c1cc500fe24a4538a81089e6c957a1f6",
      "msg_id": "",
      "outputs": []
     }
    },
    "dabd3820ac70497b8af3f6eaba30dd76": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "db8a1a3bf026432db24d0ea253f7dd87": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a410d79870cd4e24a4e4bdeffe6c7ae9",
      "placeholder": "",
      "style": "IPY_MODEL_dabd3820ac70497b8af3f6eaba30dd76",
      "value": "100%"
     }
    },
    "e5151e91dfec48939ea421a2ba8435af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e80326902e724ff28335112a88ddb587": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eaa036f5881647b0b4392e9ebe2d396f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f1a52b1d813e4bbeac7634dc622cf738": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ButtonView",
      "button_style": "",
      "description": "Submit",
      "disabled": false,
      "icon": "",
      "layout": "IPY_MODEL_2328339d8256480da2d5b1c8f51830c8",
      "style": "IPY_MODEL_7cee0e4dcae744708847c5549b69786a",
      "tooltip": ""
     }
    },
    "f6bbd18c5606487eac25577aa8e996eb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f9df21b9c0404dc0811fc923ebe4ef53": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fd32d1f08d5a423294b5d584dc991d31": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_794641c9927048ae9b82af8e676c6750",
      "placeholder": "",
      "style": "IPY_MODEL_eaa036f5881647b0b4392e9ebe2d396f",
      "value": " 1/1 [05:34&lt;00:00, 334.84s/chunk of vectors]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
