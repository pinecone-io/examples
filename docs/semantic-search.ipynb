{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7Lc9I6taO3k"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pinecone-io/examples/blob/master/docs/semantic-search.ipynb) [![Open nbviewer](https://raw.githubusercontent.com/pinecone-io/examples/master/assets/nbviewer-shield.svg)](https://nbviewer.org/github/pinecone-io/examples/blob/master/docs/semantic-search.ipynb)\n",
        "\n",
        "# Semantic Search\n",
        "\n",
        "In this walkthrough we will see how to use Pinecone for semantic search, using a multilingual translation dataset. To begin we must install the required prerequisite libraries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q03L1BYEZQfe",
        "outputId": "19ee9678-91b3-4b53-ab2e-f1c6156fa01e"
      },
      "outputs": [],
      "source": [
        "!pip install -qU \\\n",
        "  pinecone==6.0.2 \\\n",
        "  pinecone-notebooks==0.1.1 \\\n",
        "  datasets==3.5.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xmobBcgqKEL"
      },
      "source": [
        "---\n",
        "\n",
        "ðŸš¨ _Note: the above `pip install` is formatted for Jupyter notebooks. If running elsewhere you may need to drop the `!`._\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrSfFiIC5roI"
      },
      "source": [
        "## Data Download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pinecone API key not found in environment.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "def get_pinecone_api_key():\n",
        "    \"\"\"\n",
        "    Get Pinecone API key from environment variable or prompt user for input.\n",
        "    Returns the API key as a string.\n",
        "    \"\"\"\n",
        "    api_key = os.environ.get(\"PINECONE_API_KEY\")\n",
        "    \n",
        "    if not api_key:\n",
        "        try:\n",
        "            # Try Colab authentication if available\n",
        "            from pinecone_notebooks.colab import Authenticate\n",
        "            Authenticate()\n",
        "            # If successful, key will now be in environment\n",
        "            api_key = os.environ.get(\"PINECONE_API_KEY\")\n",
        "        except ImportError:\n",
        "            # If not in Colab or authentication fails, prompt user\n",
        "            print(\"Pinecone API key not found in environment.\")\n",
        "            api_key = getpass(\"Please enter your Pinecone API key: \")\n",
        "            # Save to environment for future use in session\n",
        "            os.environ[\"PINECONE_API_KEY\"] = api_key\n",
        "    \n",
        "    return api_key\n",
        "\n",
        "# Initialize Pinecone client with API key\n",
        "api_key = get_pinecone_api_key()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mc66NEBAcQHY"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/miniconda3/envs/pinecone-examples/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from pinecone import Pinecone\n",
        "\n",
        "# Initialize client\n",
        "pc = Pinecone(api_key=api_key)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creating a Pinecone Index\n",
        "\n",
        "When creating the index we need to define several configuration properties. \n",
        "\n",
        "- `name` can be anything we like. The name is used as an identifier for the index when performing other operations such as `describe_index`, `delete_index`, and so on. \n",
        "- `metric` specifies the similarity metric that will be used later when you make queries to the index.\n",
        "- `dimension` should correspond to the dimension of the dense vectors produced by your embedding model. In this quick start, we are using made-up data so a small value is simplest.\n",
        "- `spec` holds a specification which tells Pinecone how you would like to deploy our index. You can find a list of all [available providers and regions here](https://docs.pinecone.io/docs/projects).\n",
        "\n",
        "There are more configurations available, but this minimal set will get us started."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kT8pfoO46Iwg",
        "outputId": "0fec19be-c74d-4602-bec6-24d61cfc5bb4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'dimension': 1024,\n",
              " 'index_fullness': 0.0,\n",
              " 'metric': 'cosine',\n",
              " 'namespaces': {'english-sentences': {'vector_count': 416}},\n",
              " 'total_vector_count': 416,\n",
              " 'vector_type': 'dense'}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "index_name = \"semantic-search\"\n",
        "\n",
        "if not pc.has_index(index_name):\n",
        "    pc.create_index_for_model(\n",
        "        name=index_name,\n",
        "        cloud=\"aws\",\n",
        "        region=\"us-east-1\",\n",
        "        embed={\n",
        "            \"model\":\"multilingual-e5-large\",\n",
        "            \"field_map\":{\"text\": \"chunk_text\"}\n",
        "        }\n",
        "    )\n",
        "\n",
        "# Initialize index client\n",
        "index = pc.Index(name=index_name)\n",
        "\n",
        "# View index stats\n",
        "index.describe_index_stats()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating our dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "# specify that we want the english-spanish translation pairs\n",
        "tatoeba = load_dataset(\"Helsinki-NLP/tatoeba\", lang1=\"en\", lang2=\"es\", trust_remote_code=True, split=\"train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "keywords= [\"park\"]\n",
        "namespace = \"english-sentences\"\n",
        "\n",
        "def simple_keyword_filter(sentence, keywords):\n",
        "  # filter for a list of keywords by sentence\n",
        "    for keyword in keywords:\n",
        "        if keyword in sentence:\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "def transform_dataset_for_pinecone(dataset, use_filter=True):\n",
        "    # Feel free to adjust this code to simulate a larger search!\n",
        "\n",
        "    if use_filter:\n",
        "        # filter for a list of keywords by sentence, helpful for building intuition on semantic search\n",
        "        translation_pairs = dataset.filter(lambda x: simple_keyword_filter(\n",
        "        sentence = x[\"translation\"][\"en\"], keywords=keywords))\n",
        "    else:\n",
        "        # use the full 200k+ dataset\n",
        "        translation_pairs = dataset\n",
        "\n",
        "    # flatten and shuffle for ease of use\n",
        "    translation_pairs = translation_pairs.flatten()\n",
        "    translation_pairs = translation_pairs.shuffle(seed=1)\n",
        "\n",
        "    english_sentences = translation_pairs.rename_column(\"translation.en\", \"text\").remove_columns(\"translation.es\")\n",
        "\n",
        "    # add lang column to indicate embedding origin\n",
        "    english_sentences = english_sentences.add_column(\"lang\", [\"en\"]*len(english_sentences))\n",
        "\n",
        "\n",
        "    records = []\n",
        "\n",
        "    for idx, sentence in enumerate(english_sentences):\n",
        "        records.append(\n",
        "            {\n",
        "                \"id\": str(idx),\n",
        "                \"chunk_text\": sentence[\"text\"],\n",
        "                \"lang\": sentence[\"lang\"]\n",
        "            }\n",
        "        )\n",
        "\n",
        "    # convert to record format\n",
        "    return records\n",
        "\n",
        "\n",
        "records = transform_dataset_for_pinecone(tatoeba)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Upserting data into the Pinecone index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "6c9efda7c7394404814e7466d4a9108c",
            "ee94a2a6c50b4abd89fdea7dc2c51b0b",
            "1af0d3d6e7a0465a91fd27a916a0508a",
            "86cf0f742de14c4f95fa5ddb74e07985",
            "ab1007c06e414b2da35507a90e91e8cb",
            "640ee2f088814e6c80014be268749820",
            "e1d5e0366eee4a96bf4a52ee84698c6a",
            "726dc10996c5403d8b0d661a3a6cdb63",
            "1e213f554e8f4c18a96bc71b56d8582a",
            "c62d67ae4d0e498fbf330db34ca8f9e3",
            "15e5e36e202c40fba34e92adfe8aa8de"
          ]
        },
        "id": "RhR6WOi1huXZ",
        "outputId": "9ae50bfe-3ebf-4d8b-e28e-3230aed0e1d7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Upserting records batch: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:04<00:00,  1.08it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "batch_size = 96\n",
        "\n",
        "for start in tqdm(range(0, len(records), batch_size), f\"Upserting records batch: \"):\n",
        "    index.upsert_records(records=records[start:start+batch_size], namespace = namespace)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrK_IN079Vuu"
      },
      "source": [
        "## Making Queries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rr4unPAq9alb"
      },
      "source": [
        "Now that our index is populated we can begin making queries. We are performing a semantic search for *similar questions*, so we should embed and search with another question. Let's begin."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence: I have the afternoon off today, so I plan to go to the park, sit under a tree and read a book. Semantic Similarity Score: 0.8618664741516113\n",
            "\n",
            "Sentence: Let's go to the park where it's not noisy. Semantic Similarity Score: 0.8589204549789429\n",
            "\n",
            "Sentence: Let's go to the park where it is not noisy. Semantic Similarity Score: 0.8587626814842224\n",
            "\n",
            "Sentence: Let's go to the park where it isn't noisy. Semantic Similarity Score: 0.858618438243866\n",
            "\n",
            "Sentence: I go to the park. Semantic Similarity Score: 0.8583135604858398\n",
            "\n",
            "Sentence: I'll go to the park. Semantic Similarity Score: 0.8503443598747253\n",
            "\n",
            "Sentence: I like going for a walk in the park. Semantic Similarity Score: 0.8475707769393921\n",
            "\n",
            "Sentence: Let's take a walk in the park. Semantic Similarity Score: 0.8399624228477478\n",
            "\n",
            "Sentence: Who wants to go to the park? Semantic Similarity Score: 0.83930504322052\n",
            "\n",
            "Sentence: Do you like to walk in the park? Semantic Similarity Score: 0.8344495296478271\n",
            "\n"
          ]
        }
      ],
      "source": [
        "search_query = \"I want to go to the park and relax\"\n",
        "\n",
        "results = index.search(\n",
        "    namespace=namespace,\n",
        "    query={\n",
        "        \"top_k\": 10,\n",
        "        \"inputs\": {\n",
        "            'text': search_query\n",
        "        }\n",
        "    }\n",
        ")\n",
        "\n",
        "for result in results[\"result\"][\"hits\"]:\n",
        "    print(f'Sentence: {result[\"fields\"][\"chunk_text\"]} Semantic Similarity Score: {result[\"_score\"]}\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Demo Cleanup\n",
        "\n",
        "You can go ahead and ask more questions above. When you're done, delete the index to save resources:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-cWdeKzhAtww"
      },
      "outputs": [],
      "source": [
        "#pc.delete_index(name=index_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2B0zxR6hbf5d"
      },
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
