{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SMFUgtvbFeLQ"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pinecone-io/examples/blob/master/docs/gen-qa-openai.ipynb) [![Open nbviewer](https://raw.githubusercontent.com/pinecone-io/examples/master/assets/nbviewer-shield.svg)](https://nbviewer.org/github/pinecone-io/examples/blob/master/docs/gen-qa-openai.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v0to-QXCQjsm"
   },
   "source": [
    "# Retrieval Augemented Generation with Pinecone, Langchain and OpenAI\n",
    "\n",
    "#### Fixing LLMs that Hallucinate\n",
    "\n",
    "In this notebook we will learn how to query relevant contexts to our queries from Pinecone, and pass these to a generative OpenAI model to generate an answer backed by real data sources. Required installs for this notebook are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VpMvHAYRQf9N",
    "outputId": "42705370-c5bf-417b-fe8a-3f6d0fe28fbb"
   },
   "outputs": [],
   "source": [
    "!pip install -qU \\\n",
    "    \"langchain[openai]\"\\\n",
    "    langchain-text-splitters==0.3.8 \\\n",
    "    langchain-pinecone==0.2.1 \\\n",
    "    pinecone-notebooks==0.1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NhWnLkHqmeWI"
   },
   "source": [
    "---\n",
    "\n",
    "## Building a Knowledge Base\n",
    "\n",
    "Building more reliable LLMs tools requires an external _\"Knowledge Base\"_, a place where we can store and use to efficiently retrieve information. We can think of this as the external _long-term memory_ of our LLM. Typically, this takes the form of a vector database like Pinecone.\n",
    "\n",
    "We will need to retrieve information that is semantically related to our queries, to do this we need to use _\"dense vector embeddings\"_. These can be thought of as numerical representations of the *meaning* behind our sentences.\n",
    "\n",
    "There are many options for creating these dense vectors, like open source [sentence transformers embedding models](https://pinecone.io/learn/nlp/) or OpenAI's [text-embedding-3-small model](https://platform.openai.com/docs/models/text-embedding-3-small). We will use OpenAI's offering in this example.\n",
    "\n",
    "### Demo Data: Pinecone Documentation\n",
    "\n",
    "A great example to use RAG is when augmented LLMs with information that may not exist in their training data. This could private data, internal company information, or data that has been updated post a training cutoff. In our case, many modern LLMs are trained on Pinecone libraries that have since been updated, such as release notes or quickstart guides.\n",
    "\n",
    "In this example, we'll show the differences in generation from OpenAI's LLMs when asked about implementing Pinecone! We'll orchestrate our RAG workflow using Langchain, a popular framework for AI applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Getting our Dataset: \n",
    "\n",
    "release_notes_2025 = \"https://docs.pinecone.io/release-notes/2025.md\"\n",
    "release_notes_2024 = \"https://docs.pinecone.io/release-notes/2024.md\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "EI2iYxq16or9",
    "outputId": "55a8dd92-34e1-4237-a5c4-76016346999d"
   },
   "outputs": [],
   "source": [
    "# We'll grab these urls and parse them using Langchain's textsplitter for markdown\n",
    "from langchain_text_splitters import MarkdownHeaderTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "import requests\n",
    "\n",
    "splitter = MarkdownHeaderTextSplitter(headers_to_split_on=[(\"#\", \"release\"), (\"##\", \"month_year\"), (\"###\", \"feature\")])\n",
    "\n",
    "def download_link(url):\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    return response.text\n",
    "\n",
    "\n",
    "def add_document_metadata(doc, new_metadata):\n",
    "    # returns new documents with updated metadata\n",
    "    old_metadata = doc.metadata\n",
    "    new_metadata = {**old_metadata, **new_metadata}\n",
    "    return Document(page_content=doc.page_content, metadata=new_metadata)\n",
    "\n",
    "\n",
    "def preprocess_pinecone_docs(urls):\n",
    "\n",
    "    pinecone_docs = []\n",
    "    for url in urls:\n",
    "        # download the markdown\n",
    "        response = download_link(url)\n",
    "        split_text = splitter.split_text(response)\n",
    "        # Update metadata to include url as source  \n",
    "        split_text = [add_document_metadata(doc, {\"source\": url, \"chunk_num\": num}) for num, doc in enumerate(split_text)]\n",
    "        pinecone_docs.extend(split_text)\n",
    "    return pinecone_docs\n",
    "\n",
    "\n",
    "pinecone_docs = preprocess_pinecone_docs([release_notes_2024,release_notes_2025])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a closer look at one of these rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document content:  Pinecone Assistant can now [return a JSON response](/guides/assistant/chat-with-assistant#json-response).  \n",
      "***  \n",
      "You can now [create an assistant](/reference/api/2025-01/assistant/create_assistant) in the `eu` region.\n",
      "</Update>  \n",
      "<Update label=\"2024-12-17\" tags={[\"Database\"]}>\n",
      "Document metadata:  {'release': '2024 releases', 'month_year': 'December 2024', 'feature': 'Pinecone Assistant JSON mode and EU region deployment', 'source': 'https://docs.pinecone.io/release-notes/2024.md', 'chunk_num': 2}\n"
     ]
    }
   ],
   "source": [
    "print(\"Document content: \", pinecone_docs[2].page_content)\n",
    "print(\"Document metadata: \", pinecone_docs[2].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document content:  Released [`v2.2.0`](https://github.com/pinecone-io/go-pinecone/releases/tag/v2.2.0) of the [Pinecone Go SDK](/reference/go-sdk). This version adds support for [index tags](/guides/manage-data/manage-indexes#configure-index-tags) when creating or configuring indexes.\n",
      "</Update>\n",
      "Document metadata:  {'release': '2025 releases', 'month_year': 'January 2025', 'feature': 'Released Go SDK v2.2.0', 'source': 'https://docs.pinecone.io/release-notes/2025.md', 'chunk_num': 47}\n"
     ]
    }
   ],
   "source": [
    "print(\"Document content: \", pinecone_docs[-1].page_content)\n",
    "print(\"Document metadata: \", pinecone_docs[-1].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Pinecone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "def get_pinecone_api_key():\n",
    "    \"\"\"\n",
    "    Get Pinecone API key from environment variable or prompt user for input.\n",
    "    Returns the API key as a string.\n",
    "\n",
    "    Only necessary for notebooks. When using Pinecone yourself, \n",
    "    you can use environment variables or the like to set your API key.\n",
    "    \"\"\"\n",
    "    api_key = os.environ.get(\"PINECONE_API_KEY\")\n",
    "    \n",
    "    if api_key is None:\n",
    "        try:\n",
    "            # Try Colab authentication if available\n",
    "            from pinecone_notebooks.colab import Authenticate\n",
    "            Authenticate()\n",
    "            # If successful, key will now be in environment\n",
    "            api_key = os.environ.get(\"PINECONE_API_KEY\")\n",
    "        except ImportError:\n",
    "            # If not in Colab or authentication fails, prompt user for API key\n",
    "            print(\"Pinecone API key not found in environment.\")\n",
    "            api_key = getpass(\"Please enter your Pinecone API key: \")\n",
    "            # Save to environment for future use in session\n",
    "            os.environ[\"PINECONE_API_KEY\"] = api_key\n",
    "    \n",
    "    return api_key\n",
    "\n",
    "PINECONE_API_KEY = get_pinecone_api_key()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup OpenAI API Key\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_openai_api_key():\n",
    "    \"\"\"\n",
    "    Get OpenAI API key from environment variable or prompt user for input.\n",
    "    Returns the API key as a string.\n",
    "    \"\"\"\n",
    "\n",
    "    api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "    \n",
    "    if api_key is None:\n",
    "        try:\n",
    "            api_key = getpass(\"Please enter your OpenAI API key: \")\n",
    "            # Save to environment for future use in session\n",
    "            os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "        except Exception as e:\n",
    "            print(f\"Error getting OpenAI API key: {e}\")\n",
    "            return None\n",
    "    \n",
    "    return api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = get_openai_api_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "\n",
    "pc = Pinecone(\n",
    "        api_key=PINECONE_API_KEY,\n",
    "        # You can remove this parameterfor your own projects\n",
    "        source_tag=\"pinecone_examples:docs:langchain_retrieval_augmentation\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'': {'vector_count': 18}},\n",
       " 'total_vector_count': 18}"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_name = \"langchain-pinecone-rag\"\n",
    "from pinecone import ServerlessSpec\n",
    "\n",
    "if not pc.has_index(index_name):\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        # dimension of the vector embeddings produced by OpenAI's text-embedding-3-small\n",
    "        dimension=1536,\n",
    "        metric=\"cosine\",\n",
    "        # parameters for the free tier index\n",
    "        spec=ServerlessSpec(\n",
    "            cloud=\"aws\",\n",
    "            region=\"us-east-1\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Initialize index client\n",
    "index = pc.Index(name=index_name)\n",
    "\n",
    "# View index stats\n",
    "index.describe_index_stats()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding our documents and upserting into Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2024#0',\n",
       " '2024#1',\n",
       " '2024#2',\n",
       " '2024#3',\n",
       " '2024#4',\n",
       " '2024#5',\n",
       " '2024#6',\n",
       " '2024#7',\n",
       " '2024#8',\n",
       " '2024#9',\n",
       " '2024#10',\n",
       " '2024#11',\n",
       " '2024#12',\n",
       " '2024#13',\n",
       " '2024#14',\n",
       " '2024#15',\n",
       " '2024#16',\n",
       " '2024#17',\n",
       " '2024#18',\n",
       " '2024#19',\n",
       " '2024#20',\n",
       " '2024#21',\n",
       " '2024#22',\n",
       " '2024#23',\n",
       " '2024#24',\n",
       " '2024#25',\n",
       " '2024#26',\n",
       " '2024#27',\n",
       " '2024#28',\n",
       " '2024#29',\n",
       " '2024#30',\n",
       " '2024#31',\n",
       " '2024#32',\n",
       " '2024#33',\n",
       " '2024#34',\n",
       " '2024#35',\n",
       " '2024#36',\n",
       " '2024#37',\n",
       " '2024#38',\n",
       " '2024#39',\n",
       " '2024#40',\n",
       " '2024#41',\n",
       " '2025#0',\n",
       " '2025#1',\n",
       " '2025#2',\n",
       " '2025#3',\n",
       " '2025#4',\n",
       " '2025#5',\n",
       " '2025#6',\n",
       " '2025#7',\n",
       " '2025#8',\n",
       " '2025#9',\n",
       " '2025#10',\n",
       " '2025#11',\n",
       " '2025#12',\n",
       " '2025#13',\n",
       " '2025#14',\n",
       " '2025#15',\n",
       " '2025#16',\n",
       " '2025#17',\n",
       " '2025#18',\n",
       " '2025#19',\n",
       " '2025#20',\n",
       " '2025#21',\n",
       " '2025#22',\n",
       " '2025#23',\n",
       " '2025#24',\n",
       " '2025#25',\n",
       " '2025#26',\n",
       " '2025#27',\n",
       " '2025#28',\n",
       " '2025#29',\n",
       " '2025#30',\n",
       " '2025#31',\n",
       " '2025#32',\n",
       " '2025#33',\n",
       " '2025#34',\n",
       " '2025#35',\n",
       " '2025#36',\n",
       " '2025#37',\n",
       " '2025#38',\n",
       " '2025#39',\n",
       " '2025#40',\n",
       " '2025#41',\n",
       " '2025#42',\n",
       " '2025#43',\n",
       " '2025#44',\n",
       " '2025#45',\n",
       " '2025#46',\n",
       " '2025#47']"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "embeddings = OpenAIEmbeddings(api_key=OPENAI_API_KEY, model=\"text-embedding-3-small\")\n",
    "\n",
    "vector_store = PineconeVectorStore(index=index, embedding=embeddings)\n",
    "\n",
    "\n",
    "# do url_title, chunk_num to enable subscriptable hashing and replacement\n",
    "\n",
    "def clean_url_for_title(url):\n",
    "    # grabs the end of the url minus .md\n",
    "    return url.split(\"/\")[-1].replace(\".md\", \"\")\n",
    "\n",
    "# Here, we follow a schema that puts the document name, and the chunk number together, like doc1#chunk1\n",
    "\n",
    "def generate_ids(docs):\n",
    "    return f\"release{clean_url_for_title(docs.metadata['source'])}#chunk_num{docs.metadata['chunk_num']}\"\n",
    "\n",
    "ids = [generate_ids(doc) for doc in pinecone_docs]\n",
    "\n",
    "\n",
    "# To learn more, look here: https://docs.pinecone.io/guides/manage-data/manage-document-chunks\n",
    "\n",
    "vector_store.add_documents(documents=pinecone_docs, ids=ids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A5dDWPGoIrd9"
   },
   "source": [
    "## Building a chat completion prompt with relevant context\n",
    "\n",
    "Next, we write some functions to retrieve these relevant contexts from Pinecone and incorporate them into a richer chat completion prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Tell me about versions 7.0 of the Pinecone Python SDK\"\n",
    "\n",
    "retrieved_docs = vector_store.similarity_search(query)\n",
    "docs_content = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "\n",
    "prompt = f'''You are an assistant that answers question exclusively about the Pinecone SDK release notes:\n",
    "\n",
    "Here's a question: {query}\n",
    "\n",
    "Here's some context from the release notes:\n",
    "\n",
    "{docs_content}\n",
    "\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Answer:\n",
    "'''\n",
    "\n",
    "answer = llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sjOBIQ5rFeLZ"
   },
   "source": [
    "Once we're done with the index we can delete our index to save resources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Released [`v7.0.1`](https://github.com/pinecone-io/pinecone-python-client/releases/tag/v7.0.1) and [`v7.0.2`](https://github.com/pinecone-io/pinecone-python-client/releases/tag/v7.0.2) of the [Pinecone Python SDK](/reference/python-sdk). These versions fix minor bugs discovered since the release of the `v7.0.0` major version.\n",
      "</Update>  \n",
      "<Update label=\"2025-05-29\" tags={[\"SDK\"]}>\n",
      "{'chunk_num': 4.0, 'feature': 'Released Python SDK v7.0.1 and v7.0.2', 'month_year': 'May 2025', 'release': '2025 releases', 'source': 'https://docs.pinecone.io/release-notes/2025.md'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Released [`v7.0.0`](https://github.com/pinecone-io/pinecone-python-client/releases/tag/v7.0.0) of the [Pinecone Python SDK](/reference/python-sdk). This version uses the latest stable API version, `2025-04`, and includes support for the following:  \n",
      "* [Creating and managing backups](/guides/manage-data/back-up-an-index)\n",
      "* [Restoring indexes from backups](/guides/manage-data/restore-an-index)\n",
      "* [Listing embedding and reranking models hosted by Pinecone](/reference/api/2025-04/inference/list_models)\n",
      "* [Getting details about a model hosted by Pinecone](/reference/api/2025-04/inference/describe_model)\n",
      "* [Creating a BYOC index](/guides/production/bring-your-own-cloud#create-an-index)  \n",
      "Additionally, the `pinecone-plugin-assistant` package required to work with [Pinecone Assistant](/guides/assistant/overview) is now included by default; it is no longer necessary to install the plugin separately.\n",
      "</Update>  \n",
      "<Update label=\"2025-05-19\" tags={[\"SDK\"]}>\n",
      "{'chunk_num': 7.0, 'feature': 'Released Python SDK v7.0.0', 'month_year': 'May 2025', 'release': '2025 releases', 'source': 'https://docs.pinecone.io/release-notes/2025.md'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Released [`v6.0.0`](https://github.com/pinecone-io/pinecone-python-client/releases/tag/v6.0.0) of the [Pinecone Python SDK](/reference/python-sdk). This version uses the latest stable API version, `2025-01`, and includes support for the following:  \n",
      "* [Index tags](/guides/manage-data/manage-indexes#configure-index-tags) to categorize and identify your indexes.\n",
      "* [Integrated inference](/reference/api/introduction#inference) without the need for extra plugins. If you were using the preview functionality of integrated inference, you must uninstall the `pinecone-plugin-records` package to use the `v6.0.0` release.\n",
      "* Enum objects to help with the discoverability of some configuration options, for example, `Metric`, `AwsRegion`, `GcpRegion`, `PodType`, `EmbedModel`, `RerankModel`. This is a backwards compatible change; you can still pass string values for affected fields.\n",
      "* New client variants, `PineconeAsyncio` and `IndexAsyncio`, which provide `async` methods for use with [asyncio](https://docs.python.org/3/library/asyncio.html). This makes it possible to use Pinecone with modern async web frameworks such as [FastAPI](https://fastapi.tiangolo.com/), [Quart](https://quart.palletsprojects.com/en/latest/), and [Sanic](https://sanic.dev/en/). Async support should significantly increase the efficiency of running many upserts in parallel.  \n",
      "<Warning>\n",
      "Before upgrading to `v6.0.0`, update all relevant code to account for the following [breaking changes](/reference/api/versioning#breaking-changes). See the [`v6.0.0`](https://github.com/pinecone-io/pinecone-python-client/releases/tag/v6.0.0) release notes for full details.  \n",
      "* Incorporated the `pinecone-plugin-records` and `pinecone-plugin-inference` plugins into the `pinecone` package. If you are using these plugins, you must unstall them to use `v6.0.0`.\n",
      "* Dropped support for Python 3.8, which has now reached official end of life, and added support for Python 3.13.\n",
      "* Removed the explicit dependency on `tqdm`, which is used to provide a progress bar when upserting data into Pinecone. If `tqdm` is available in the environment, the Pinecone SDK will detect and use it, but `tdqm` is no longer required to run the SDK. Popular notebook platforms such as [Jupyter](https://jupyter.org/) and [Google Colab](https://colab.google/) already include `tqdm` in the environment by default, but if you are running small scripts in other environments and want to continue seeing progress bars, you will need to separately install the `tqdm` package.\n",
      "* Removed some previously deprecated and rarely used keyword arguments (`config`, `openapi_config`, and `index_api`) to instead prefer dedicated keyword arguments for individual settings such as `api_key`, `proxy_url`, etc.\n",
      "</Warning>\n",
      "</Update>  \n",
      "<Update label=\"2025-02-07\" tags={[\"SDK\"]}>\n",
      "{'chunk_num': 38.0, 'feature': 'Released Python SDK v6.0.0', 'month_year': 'February 2025', 'release': '2025 releases', 'source': 'https://docs.pinecone.io/release-notes/2025.md'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Released [`v4.0.0`](https://github.com/pinecone-io/pinecone-ts-client/releases/tag/v4.0.0) of the [Pinecone Node.js SDK](/reference/node-sdk). This version uses the latest stable API version, `2024-10`, and adds support for [reranking](/guides/search/rerank-results) and [import](/guides/index-data/import-data).  \n",
      "***  \n",
      "Released [`v2.0.0`](https://github.com/pinecone-io/go-pinecone/releases/tag/v2.0.0) of the [Pinecone Go SDK](/reference/go-sdk). This version uses the latest stable API version, `2024-10`, and adds support for [reranking](/guides/search/rerank-results) and [import](/guides/index-data/import-data).  \n",
      "***  \n",
      "Released [`v3.0.0`](https://github.com/pinecone-io/pinecone-java-client/releases/tag/v3.0.0) of the [Pinecone Java SDK](/reference/java-sdk). This version uses the latest stable API version, `2024-10`, and adds support for [embedding](/reference/api/2025-01/inference/generate-embeddings), [reranking](/reference/api/2025-01/inference/rerank), and [import](/guides/index-data/import-data).  \n",
      "<Warning>\n",
      "`v3.0.0` also includes the following [breaking change](/reference/api/versioning#breaking-changes): The `control` class has been renamed `db_control`. Before upgrading to this version, be sure to update all relevant `import` statements to account for this change.  \n",
      "For example, you would change `import org.openapitools.control.client.model.*;` to `import org.openapitools.db_control.client.model.*;`.\n",
      "</Warning>  \n",
      "***  \n",
      "`v5.3.0` and `v5.3.1` of the [Pinecone Python SDK](/reference/python-sdk) use the latest stable API version, `2024-10`. These versions were release previously.\n",
      "</Update>  \n",
      "<Update label=\"2024-10-24\" tags={[\"API\"]}>\n",
      "{'chunk_num': 26.0, 'feature': 'Released major SDK updates: Node.js, Go, Java, and Python', 'month_year': 'October 2024', 'release': '2024 releases', 'source': 'https://docs.pinecone.io/release-notes/2024.md'}\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for d in retrieved_docs:\n",
    "    print(d.page_content)\n",
    "    print(d.metadata)\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versions 7.0 of the Pinecone Python SDK include the following releases:\n",
      "\n",
      "1. **v7.0.0** (Released on May 29, 2025):\n",
      "   - This major version uses the latest stable API version, `2025-04`.\n",
      "   - New features include:\n",
      "     - Support for creating and managing backups.\n",
      "     - Ability to restore indexes from backups.\n",
      "     - Listing embedding and reranking models hosted by Pinecone.\n",
      "     - Getting details about a model hosted by Pinecone.\n",
      "     - Creating a Bring Your Own Cloud (BYOC) index.\n",
      "   - The `pinecone-plugin-assistant` package is now included by default, eliminating the need for separate installation.\n",
      "\n",
      "2. **v7.0.1** and **v7.0.2** (Released after v7.0.0):\n",
      "   - These versions fix minor bugs discovered since the release of v7.0.0.\n",
      "\n",
      "For further details, you can reference the links to the release notes for each version:\n",
      "- [v7.0.0 Release Notes](https://github.com/pinecone-io/pinecone-python-client/releases/tag/v7.0.0)\n",
      "- [v7.0.1 Release Notes](https://github.com/pinecone-io/pinecone-python-client/releases/tag/v7.0.1)\n",
      "- [v7.0.2 Release Notes](https://github.com/pinecone-io/pinecone-python-client/releases/tag/v7.0.2)\n"
     ]
    }
   ],
   "source": [
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of my last update in October 2023, the Pinecone Python SDK had undergone several updates and feature releases that improved its usability and functionality. However, for the most recent specific feature release details, I would recommend checking the official Pinecone GitHub repository or the Pinecone documentation site, as these resources would provide the latest updates, feature announcements, and version release notes.\n",
      "\n",
      "Typically, significant feature releases in SDKs like Pinecone might include improvements in performance, additional methods for data querying, enhanced support for vector similarity searches, or new integrations with other machine learning tools and frameworks. Always refer to the official communication channels for the most accurate and up-to-date information.\n"
     ]
    }
   ],
   "source": [
    "print(llm.invoke(\"Tell about the most recent major feature release in the Pinecone Python SDK\").content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "id": "PpJp-xExFeLa"
   },
   "outputs": [],
   "source": [
    "pc.delete_index(name=index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2kNh44bEFeLe"
   },
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "57376684f67c5d7b1589c855d7d0f1a1bdf8944ab1b903e711fdbf39434567bb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
