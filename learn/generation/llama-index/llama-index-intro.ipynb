{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "s4eK-unQlKTF"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pinecone-io/examples/blob/master/learn/generation/llama-index/llama-index-intro.ipynb) [![Open nbviewer](https://raw.githubusercontent.com/pinecone-io/examples/master/assets/nbviewer-shield.svg)](https://nbviewer.org/github/pinecone-io/examples/blob/master/learn/generation/llama-index/llama-index-intro.ipynb)\n",
        "\n",
        "# Llama-Index with Pinecone\n",
        "\n",
        "In this notebook, we will demo how to use the `llama-index` (previously GPT-index) library with Pinecone for semantic search. This notebook is an introduction and does not cover the more advanced features of `llama-index`. You will find these in future releases in the [Pinecone examples repo](https://github.com/pinecone-io/examples/tree/master/learn/generation).\n",
        "\n",
        "We will start by installing the necessary libraries and initializing Pinecone."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "YenjP38jtRdE"
      },
      "outputs": [],
      "source": [
        "!pip install -qU llama-index datasets pinecone-client openai transformers"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "KjeiHqOIoGnI"
      },
      "source": [
        "We can go ahead and load the **SQuAD** dataset, which contains questions and answer pairs from Wikipedia articles. We'll then convert the dataset into a pandas DataFrame and keep only the unique 'context' fields, which are the text passages that the questions are based on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "TlKkc8Jbqiin",
        "outputId": "34a6aa74-477e-45bf-fede-4d89603c291b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:datasets.builder:Found cached dataset squad (/root/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3a7fad2c-e866-4e72-939d-b7f984365935\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>context</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5733be284776f41900661182</td>\n",
              "      <td>Architecturally, the school has a Catholic cha...</td>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5733bf84d058e614000b61be</td>\n",
              "      <td>As at most other universities, Notre Dame's st...</td>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>5733bed24776f41900661188</td>\n",
              "      <td>The university is the major seat of the Congre...</td>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>5733a6424776f41900660f51</td>\n",
              "      <td>The College of Engineering was established in ...</td>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>5733a70c4776f41900660f64</td>\n",
              "      <td>All of Notre Dame's undergraduate students are...</td>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3a7fad2c-e866-4e72-939d-b7f984365935')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3a7fad2c-e866-4e72-939d-b7f984365935 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3a7fad2c-e866-4e72-939d-b7f984365935');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                          id  \\\n",
              "0   5733be284776f41900661182   \n",
              "5   5733bf84d058e614000b61be   \n",
              "10  5733bed24776f41900661188   \n",
              "15  5733a6424776f41900660f51   \n",
              "20  5733a70c4776f41900660f64   \n",
              "\n",
              "                                              context  \\\n",
              "0   Architecturally, the school has a Catholic cha...   \n",
              "5   As at most other universities, Notre Dame's st...   \n",
              "10  The university is the major seat of the Congre...   \n",
              "15  The College of Engineering was established in ...   \n",
              "20  All of Notre Dame's undergraduate students are...   \n",
              "\n",
              "                       title  \n",
              "0   University_of_Notre_Dame  \n",
              "5   University_of_Notre_Dame  \n",
              "10  University_of_Notre_Dame  \n",
              "15  University_of_Notre_Dame  \n",
              "20  University_of_Notre_Dame  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "data = load_dataset('squad', split='train')\n",
        "data = data.to_pandas()[['id', 'context', 'title']]\n",
        "data.drop_duplicates(subset='context', keep='first', inplace=True)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZT6Z5gW4oTkG",
        "outputId": "c4797ae0-4091-4b8e-fa63-293174deb073"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "18891"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(data)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "IK90FFhf42hd"
      },
      "source": [
        "This code transforms our DataFrame into a list of Document objects, ready for indexing with llama_index. Each document contains the text passage, a unique id, and an extra field for the article title."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXOYMGfLtO-Z",
        "outputId": "62466814-5797-40f4-c606-a163c44581e4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(text='Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.', doc_id='5733be284776f41900661182', embedding=None, doc_hash='ba8eb7d843763d4f7e7f71f0be64c70c4597fd712bfcce77007fc4c821b8d1b6', extra_info={'title': 'University_of_Notre_Dame'})"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from llama_index import Document\n",
        "\n",
        "docs = []\n",
        "\n",
        "for i, row in data.iterrows():\n",
        "    docs.append(Document(\n",
        "        text=row['context'],\n",
        "        doc_id=row['id'],\n",
        "        extra_info={'title': row['title']}\n",
        "    ))\n",
        "docs[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hG81jmfCobYF",
        "outputId": "e8813daa-98ad-4f37-a0dd-560046a1073a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "18891"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(docs)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "uQ4d9UlS5OeU"
      },
      "source": [
        "Here, we're setting up the OpenAI API key and initializing a `SimpleNodeParser`. This parser processes our list of `Document` objects into 'nodes', which are the basic units that `llama_index` uses for indexing and querying. The first node is displayed below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "1MSXio_atoSq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = 'OPENAI_API_KEY'  # platform.openai.com"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKTwFpkmte7o",
        "outputId": "f3774aa6-4fca-44a8-ae1f-58063eae50c6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Node(text='Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.', doc_id='8968aa3c-abbe-4fe0-ad91-be0298830542', embedding=None, doc_hash='ba8eb7d843763d4f7e7f71f0be64c70c4597fd712bfcce77007fc4c821b8d1b6', extra_info={'title': 'University_of_Notre_Dame'}, node_info={'start': 0, 'end': 695}, relationships={<DocumentRelationship.SOURCE: '1'>: '5733be284776f41900661182'})"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from llama_index.node_parser import SimpleNodeParser\n",
        "\n",
        "parser = SimpleNodeParser()\n",
        "\n",
        "nodes = parser.get_nodes_from_documents(docs)\n",
        "nodes[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQL4X2_WodU2",
        "outputId": "34d05a8e-1c39-4248-e4d6-25433fd31b58"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "18892"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(nodes)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JQrAcAdZ1fS9"
      },
      "source": [
        "### Indexing in Pinecone\n",
        "\n",
        "Pinecone is a managed vector database service designed for machine learning applications. We're using it in this context to store and retrieve embeddings generated by our language model, enabling efficient and scalable semantic similarity-based search.\n",
        "\n",
        "We initialize Pinecone with the relevant API key and environment that we [get for **free** in the console](https://app.pinecone.io/), then create a new index. The index has a dimension of 1536 and uses cosine similarity, which is the recommended metric for comparing vectors produced by the `text-embedding-ada-002` model we'll be using."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "9SjIHPZgy8Zr"
      },
      "outputs": [],
      "source": [
        "import pinecone\n",
        "\n",
        "# find API key in console at app.pinecone.io\n",
        "os.environ['PINECONE_API_KEY'] = 'PINECONE_API_KEY'\n",
        "# environment is found next to API key in the console\n",
        "os.environ['PINECONE_ENVIRONMENT'] = 'PINECONE_ENVIRONMENT'\n",
        "\n",
        "# initialize connection to pinecone\n",
        "pinecone.init(\n",
        "    api_key=os.environ['PINECONE_API_KEY'],\n",
        "    environment=os.environ['PINECONE_ENVIRONMENT']\n",
        ")\n",
        "\n",
        "# create the index if it does not exist already\n",
        "index_name = 'llama-index-intro'\n",
        "if index_name not in pinecone.list_indexes():\n",
        "    pinecone.create_index(\n",
        "        index_name,\n",
        "        dimension=1536,\n",
        "        metric='cosine'\n",
        "    )\n",
        "\n",
        "# connect to the index\n",
        "pinecone_index = pinecone.Index(index_name)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "r4KQXwLh645t"
      },
      "source": [
        "Here, we're initializing a `PineconeVectorStore` with our previously created Pinecone index. This object will serve as the storage and retrieval interface for our document embeddings in Pinecone's vector database."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "AO4eAvSn4t-R"
      },
      "outputs": [],
      "source": [
        "from llama_index.vector_stores import PineconeVectorStore\n",
        "\n",
        "# we can select a namespace (acts as a partition in an index)\n",
        "namespace = '' # default namespace\n",
        "\n",
        "vector_store = PineconeVectorStore(pinecone_index=pinecone_index)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qotocu00ZjfF"
      },
      "source": [
        "Next we initialize the `GPTVectorStoreIndex` with our list of `Document` objects, using the `PineconeVectorStore` as storage and `OpenAIEmbedding` model for embeddings.\n",
        "\n",
        "`StorageContext` is used to configure the storage setup, and `ServiceContext` sets up the embedding model. The `GPTVectorStoreIndex` handles the indexing and querying process, making use of the provided storage and service contexts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "V64_Y5FZqJ8w"
      },
      "outputs": [],
      "source": [
        "from llama_index import GPTVectorStoreIndex, StorageContext, ServiceContext\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "\n",
        "# setup our storage (vector db)\n",
        "storage_context = StorageContext.from_defaults(\n",
        "    vector_store=vector_store\n",
        ")\n",
        "# setup the index/query process, ie the embedding model (and completion if used)\n",
        "embed_model = OpenAIEmbedding(model='text-embedding-ada-002', embed_batch_size=100)\n",
        "service_context = ServiceContext.from_defaults(embed_model=embed_model)\n",
        "\n",
        "index = GPTVectorStoreIndex.from_documents(\n",
        "    docs, storage_context=storage_context,\n",
        "    service_context=service_context\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7veOHn3Zyv1"
      },
      "source": [
        "Finally we can build a query engine from the `index` we build and use this engine to perform a query."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4loa7g_y5x2v",
        "outputId": "e87ab48f-f641-46a1-f06b-be2d5daf4a0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "The College of Engineering was established in 1920.\n"
          ]
        }
      ],
      "source": [
        "query_engine = index.as_query_engine()\n",
        "res = query_engine.query(\"in what year was the college of engineering established at the University of Notre Dame?\")\n",
        "print(res)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xQEzZJqWaAgS"
      },
      "source": [
        "That's our quick intro to using Llama-index and Pinecone! Once we're done testing the system we should delete the Pinecone index to save resources:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "z89CVJMGaJ4j"
      },
      "outputs": [],
      "source": [
        "pinecone.delete_index(index_name)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "DWtX3Nxl5V71"
      },
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
