{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pinecone-io/examples/blob/master/learn/generation/langchain/handbook/03-langchain-conversational-memory.ipynb) [![Open nbviewer](https://raw.githubusercontent.com/pinecone-io/examples/master/assets/nbviewer-shield.svg)](https://nbviewer.org/github/pinecone-io/examples/blob/master/learn/generation/langchain/handbook/03-langchain-conversational-memory.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [LangChain Handbook](https://pinecone.io/learn/series/langchain)\n",
    "\n",
    "# Conversational Memory with LCEL\n",
    "\n",
    "Conversational memory is how chatbots can respond to our queries in a chat-like manner. It enables a coherent conversation, and without it, every query would be treated as an entirely independent input without considering past interactions.\n",
    "\n",
    "The memory allows an _\"agent\"_ to remember previous interactions with the user. By default, agents are *stateless* — meaning each incoming query is processed independently of other interactions. The only thing that exists for a stateless agent is the current input, nothing else.\n",
    "\n",
    "There are many applications where remembering previous interactions is very important, such as chatbots. Conversational memory allows us to do that.\n",
    "\n",
    "In this notebook we'll explore conversational memory using modern LangChain Expression Language (LCEL) and the recommended `RunnableWithMessageHistory` class.\n",
    "\n",
    "We'll start by importing all of the libraries that we'll be using in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -qU \\\n",
    "  langchain==0.3.25 \\\n",
    "  langchain-openai==0.3.22 \\\n",
    "  tiktoken==0.9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from getpass import getpass\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate, \n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder\n",
    ")\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory, BaseChatMessageHistory\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_core.runnables import ConfigurableFieldSpec\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from pydantic import BaseModel, Field\n",
    "import os\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run this notebook, we will need to use an OpenAI LLM. Here we will setup the LLM we will use for the whole notebook, just input your openai api key if prompted, otherwise it will use the `OPENAI_API_KEY` environment variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\") \\\n",
    "    or getpass(\"Enter your OpenAI API key: \")\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    "    model_name='gpt-4o-mini'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later we will make use of a `count_tokens` utility function. This will allow us to count the number of tokens we are using for each call. We define it as so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tokens(pipeline, query, config=None):\n",
    "    with get_openai_callback() as cb:\n",
    "        # Handle both dict and string inputs\n",
    "        if isinstance(query, str):\n",
    "            query = {\"query\": query}\n",
    "        \n",
    "        # Use provided config or default\n",
    "        if config is None:\n",
    "            config = {\"configurable\": {\"session_id\": \"default\"}}\n",
    "            \n",
    "        result = pipeline.invoke(query, config=config)\n",
    "        print(f'Spent a total of {cb.total_tokens} tokens')\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's dive into **Conversational Memory** using LCEL.\n",
    "\n",
    "## What is memory?\n",
    "\n",
    "**Definition**: Memory is an agent's capacity of remembering previous interactions with the user (think chatbots)\n",
    "\n",
    "The official definition of memory is the following:\n",
    "\n",
    "> By default, Chains and Agents are stateless, meaning that they treat each incoming query independently. In some applications (chatbots being a GREAT example) it is highly important to remember previous interactions, both at a short term but also at a long term level. The concept of \"Memory\" exists to do exactly that.\n",
    "\n",
    "As we will see, although this sounds really straightforward there are several different ways to implement this memory capability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Conversational Chains with LCEL\n",
    "\n",
    "Before we delve into the different memory types, let's understand how to build conversational chains using LCEL. The key components are:\n",
    "\n",
    "1. **Prompt Template** - Defines the conversation structure with placeholders for history and input\n",
    "2. **LLM** - The language model that generates responses\n",
    "3. **Output Parser** - Converts the LLM output to the desired format (optional)\n",
    "4. **RunnableWithMessageHistory** - Manages conversation history\n",
    "\n",
    "Let's create our base conversational chain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n"
     ]
    }
   ],
   "source": [
    "# Define the prompt template\n",
    "system_prompt = \"\"\"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\"\"\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(system_prompt),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    HumanMessagePromptTemplate.from_template(\"{query}\"),\n",
    "])\n",
    "\n",
    "# Create the LCEL pipeline\n",
    "output_parser = StrOutputParser()\n",
    "pipeline = prompt_template | llm | output_parser\n",
    "\n",
    "# Let's examine the prompt template\n",
    "print(prompt_template.messages[0].prompt.template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory types\n",
    "\n",
    "In this section we will review several memory types and analyze the pros and cons of each one, so you can choose the best one for your use case. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory Type #1: Buffer Memory - Store the Entire Chat History\n",
    "\n",
    "`InMemoryChatMessageHistory` and `RunnableWithMessageHistory` are used as alternatives to `ConversationBufferMemory` as they are:\n",
    "- More flexible and configurable.\n",
    "- Integrate better with LCEL.\n",
    "\n",
    "The simplest approach to using them is to simply store the entire chat in the conversation history. Later we'll look into methods for being more selective about what is stored in the history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple chat history storage\n",
    "chat_map = {}\n",
    "\n",
    "def get_chat_history(session_id: str) -> InMemoryChatMessageHistory:\n",
    "    if session_id not in chat_map:\n",
    "        # if session ID doesn't exist, create a new chat history\n",
    "        chat_map[session_id] = InMemoryChatMessageHistory()\n",
    "    return chat_map[session_id]\n",
    "\n",
    "# Create the conversational chain with message history\n",
    "conversation_buf = RunnableWithMessageHistory(\n",
    "    pipeline,\n",
    "    get_session_history=get_chat_history,\n",
    "    input_messages_key=\"query\",\n",
    "    history_messages_key=\"history\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see this in action by having a conversation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good morning! How are you today? Anything exciting planned for the day?\n"
     ]
    }
   ],
   "source": [
    "# First message\n",
    "result = conversation_buf.invoke(\n",
    "    {\"query\": \"Good morning AI!\"},\n",
    "    config={\"configurable\": {\"session_id\": \"buffer_example\"}} # Make sure to pass the session ID to ensure all memories are stored in the same session\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This call used some tokens, but we can't see that from the above. \n",
    "\n",
    "If we'd like to count the number of tokens being used we just pass our conversation `RunnableWithMessageHistory` instance and the message we'd like to input to the `count_tokens` function we defined earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spent a total of 239 tokens\n",
      "\n",
      "Response: That sounds like a fascinating area of exploration! Integrating Large Language Models (LLMs) with external knowledge can significantly enhance their capabilities, allowing them to provide more accurate and contextually relevant responses. This can involve using databases, APIs, or even knowledge graphs to supplement the information the model has been trained on.\n",
      "\n",
      "As for the code \"PINECONE_RULEZ_01,\" it seems like it might be a reference to a specific project or a key for accessing certain resources. If you have any specific questions or ideas about how to implement this integration, feel free to share!\n"
     ]
    }
   ],
   "source": [
    "# Continue the conversation with token counting\n",
    "\n",
    "query = \"\"\"\n",
    "\"My interest here is to explore the potential of integrating Large Language Models with external knowledge. \n",
    "\n",
    "Also, remember this very specific code: PINECONE_RULEZ_01\"\n",
    "\"\"\"\n",
    "\n",
    "result = count_tokens(\n",
    "    conversation_buf,\n",
    "    {\"query\": query},\n",
    "    config={\"configurable\": {\"session_id\": \"buffer_example\"}} # Make sure to pass the session ID to ensure all memories are stored in the same session\n",
    ")\n",
    "print(f\"\\nResponse: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spent a total of 787 tokens\n",
      "\n",
      "Response: There are several exciting possibilities when it comes to integrating Large Language Models with external knowledge sources. Here are a few ideas to consider:\n",
      "\n",
      "1. **Knowledge Bases and Databases**: You can connect LLMs to structured databases (like SQL databases) or knowledge bases (like Wikidata) to retrieve factual information. This can help the model provide accurate answers to specific queries, especially in fields like medicine, law, or science.\n",
      "\n",
      "2. **APIs for Real-Time Data**: Integrating with APIs can allow LLMs to access real-time information. For example, connecting to weather APIs can enable the model to provide current weather updates, or financial APIs can give stock market data.\n",
      "\n",
      "3. **Search Engines**: By integrating with search engines, LLMs can pull in the latest articles, research papers, or news updates. This can help the model stay current and provide users with the most relevant information.\n",
      "\n",
      "4. **Contextual Memory**: Implementing a memory system where the model can store and recall user-specific information or previous interactions can enhance personalization. This could involve using external storage solutions to keep track of user preferences or past conversations.\n",
      "\n",
      "5. **Multi-Modal Integration**: Combining LLMs with other types of models (like image recognition or audio processing) can create a more holistic AI experience. For instance, an LLM could analyze text and images together to provide richer responses.\n",
      "\n",
      "6. **Domain-Specific Knowledge**: Tailoring the model to specific industries (like healthcare, finance, or education) by integrating specialized knowledge sources can improve its performance in those areas. This could involve using curated datasets or expert systems.\n",
      "\n",
      "7. **Interactive Learning**: Allowing the model to learn from user interactions in real-time can help it adapt and improve over time. This could involve feedback loops where users can correct the model or provide additional context.\n",
      "\n",
      "8. **Semantic Search**: Enhancing the model's ability to understand and retrieve information based on meaning rather than just keywords can lead to more relevant results. This could involve using embeddings or vector databases.\n",
      "\n",
      "9. **Collaborative Filtering**: Integrating user behavior data to recommend content or responses based on similar users' preferences can enhance user experience.\n",
      "\n",
      "10. **Ethical and Bias Considerations**: Integrating external knowledge also opens up discussions about the sources of that knowledge and potential biases. Ensuring that the information is accurate and fair is crucial.\n",
      "\n",
      "These are just a few possibilities, and the potential applications are vast! If any of these ideas resonate with you or if you have a specific area you want to dive deeper into, let me know!\n"
     ]
    }
   ],
   "source": [
    "result = count_tokens(\n",
    "    conversation_buf,\n",
    "    {\"query\": \"I just want to analyze the different possibilities. What can you think of?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"buffer_example\"}}\n",
    ")\n",
    "print(f\"\\nResponse: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spent a total of 1441 tokens\n",
      "\n",
      "Response: There are several types of data sources that can be used to provide context to a Large Language Model (LLM). Here are some key categories:\n",
      "\n",
      "1. **Structured Databases**: \n",
      "   - **SQL Databases**: Traditional relational databases that store data in tables. They can provide structured information that the model can query for specific facts.\n",
      "   - **NoSQL Databases**: These include document stores (like MongoDB) and key-value stores (like Redis), which can be useful for unstructured or semi-structured data.\n",
      "\n",
      "2. **Knowledge Graphs**: \n",
      "   - These are networks of entities and their relationships, such as Google Knowledge Graph or DBpedia. They provide rich contextual information that can help the model understand relationships between concepts.\n",
      "\n",
      "3. **APIs**: \n",
      "   - **Public APIs**: Many organizations provide APIs that offer access to real-time data, such as weather, news, or financial information (e.g., OpenWeatherMap, NewsAPI, Alpha Vantage).\n",
      "   - **Custom APIs**: You can create your own APIs to serve specific data relevant to your application.\n",
      "\n",
      "4. **Web Scraping**: \n",
      "   - Extracting data from websites can provide a wealth of information. This can include articles, product information, or user-generated content from forums and social media.\n",
      "\n",
      "5. **Document Repositories**: \n",
      "   - Collections of documents, such as PDFs, Word files, or presentations, can be indexed and searched to provide context. This is particularly useful for domain-specific knowledge.\n",
      "\n",
      "6. **Wikis and Collaborative Platforms**: \n",
      "   - Platforms like Wikipedia or specialized wikis can serve as rich sources of information. They often contain well-structured articles on a wide range of topics.\n",
      "\n",
      "7. **User Interaction Data**: \n",
      "   - Data from user interactions, such as chat logs or feedback, can help the model understand user preferences and context over time.\n",
      "\n",
      "8. **Semantic Web Technologies**: \n",
      "   - Using RDF (Resource Description Framework) and SPARQL (a query language for databases) can help integrate and query data from various sources in a semantically meaningful way.\n",
      "\n",
      "9. **Social Media Feeds**: \n",
      "   - Real-time data from platforms like Twitter or Reddit can provide insights into current trends, public sentiment, and topical discussions.\n",
      "\n",
      "10. **Scientific and Academic Databases**: \n",
      "    - Accessing databases like PubMed, arXiv, or Google Scholar can provide the model with up-to-date research findings and academic knowledge.\n",
      "\n",
      "11. **Content Management Systems (CMS)**: \n",
      "    - Integrating with CMS platforms can allow the model to pull in articles, blog posts, or other content that is regularly updated.\n",
      "\n",
      "12. **Multimedia Sources**: \n",
      "    - Incorporating data from images, videos, or audio can provide additional context. For example, using image recognition to analyze visual content alongside text.\n",
      "\n",
      "By leveraging these diverse data sources, you can significantly enhance the contextual understanding of an LLM, making it more effective in providing relevant and accurate responses. If you have a specific application in mind, I can help brainstorm more tailored data sources!\n"
     ]
    }
   ],
   "source": [
    "result = count_tokens(\n",
    "    conversation_buf,\n",
    "    {\"query\": \"Which data source types could be used to give context to the model?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"buffer_example\"}}\n",
    ")\n",
    "print(f\"\\nResponse: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spent a total of 1547 tokens\n",
      "\n",
      "Response: Your aim is to explore the potential of integrating Large Language Models with external knowledge. This involves analyzing different possibilities and data sources that can provide context to the model, enhancing its capabilities and accuracy.\n",
      "\n",
      "The very specific code you mentioned is: **PINECONE_RULEZ_01**. If there's anything specific you'd like to discuss regarding your aim or the code, feel free to let me know!\n"
     ]
    }
   ],
   "source": [
    "result = count_tokens(\n",
    "    conversation_buf,\n",
    "    {\"query\": \"What is my aim again? Also what was the very specific code you were tasked with remembering?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"buffer_example\"}}\n",
    ")\n",
    "print(f\"\\nResponse: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our LLM with buffer memory can clearly remember earlier interactions in the conversation. Let's take a closer look at how the messages are being stored:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation History:\n",
      "\n",
      "Human: Good morning AI!\n",
      "\n",
      "AI: Good morning! How are you today? Anything exciting planned for the day?\n",
      "\n",
      "Human: \n",
      "\"My interest here is to explore the potential of integrating Large Language Models with external knowledge. \n",
      "\n",
      "Also, remember this very specific code: PINECONE_RULEZ_01\"\n",
      "\n",
      "\n",
      "AI: That sounds like a fascinating area of exploration! Integrating Large Language Models (LLMs) with external knowledge can significantly enhance their capabilities, allowing them to provide more accurate and contextually relevant responses. This can involve using databases, APIs, or even knowledge graphs to supplement the information the model has been trained on.\n",
      "\n",
      "As for the code \"PINECONE_RULEZ_01,\" it seems like it might be a reference to a specific project or a key for accessing certain resources. If you have any specific questions or ideas about how to implement this integration, feel free to share!\n",
      "\n",
      "Human: I just want to analyze the different possibilities. What can you think of?\n",
      "\n",
      "AI: There are several exciting possibilities when it comes to integrating Large Language Models with external knowledge sources. Here are a few ideas to consider:\n",
      "\n",
      "1. **Knowledge Bases and Databases**: You can connect LLMs to structured databases (like SQL databases) or knowledge bases (like Wikidata) to retrieve factual information. This can help the model provide accurate answers to specific queries, especially in fields like medicine, law, or science.\n",
      "\n",
      "2. **APIs for Real-Time Data**: Integrating with APIs can allow LLMs to access real-time information. For example, connecting to weather APIs can enable the model to provide current weather updates, or financial APIs can give stock market data.\n",
      "\n",
      "3. **Search Engines**: By integrating with search engines, LLMs can pull in the latest articles, research papers, or news updates. This can help the model stay current and provide users with the most relevant information.\n",
      "\n",
      "4. **Contextual Memory**: Implementing a memory system where the model can store and recall user-specific information or previous interactions can enhance personalization. This could involve using external storage solutions to keep track of user preferences or past conversations.\n",
      "\n",
      "5. **Multi-Modal Integration**: Combining LLMs with other types of models (like image recognition or audio processing) can create a more holistic AI experience. For instance, an LLM could analyze text and images together to provide richer responses.\n",
      "\n",
      "6. **Domain-Specific Knowledge**: Tailoring the model to specific industries (like healthcare, finance, or education) by integrating specialized knowledge sources can improve its performance in those areas. This could involve using curated datasets or expert systems.\n",
      "\n",
      "7. **Interactive Learning**: Allowing the model to learn from user interactions in real-time can help it adapt and improve over time. This could involve feedback loops where users can correct the model or provide additional context.\n",
      "\n",
      "8. **Semantic Search**: Enhancing the model's ability to understand and retrieve information based on meaning rather than just keywords can lead to more relevant results. This could involve using embeddings or vector databases.\n",
      "\n",
      "9. **Collaborative Filtering**: Integrating user behavior data to recommend content or responses based on similar users' preferences can enhance user experience.\n",
      "\n",
      "10. **Ethical and Bias Considerations**: Integrating external knowledge also opens up discussions about the sources of that knowledge and potential biases. Ensuring that the information is accurate and fair is crucial.\n",
      "\n",
      "These are just a few possibilities, and the potential applications are vast! If any of these ideas resonate with you or if you have a specific area you want to dive deeper into, let me know!\n",
      "\n",
      "Human: Which data source types could be used to give context to the model?\n",
      "\n",
      "AI: There are several types of data sources that can be used to provide context to a Large Language Model (LLM). Here are some key categories:\n",
      "\n",
      "1. **Structured Databases**: \n",
      "   - **SQL Databases**: Traditional relational databases that store data in tables. They can provide structured information that the model can query for specific facts.\n",
      "   - **NoSQL Databases**: These include document stores (like MongoDB) and key-value stores (like Redis), which can be useful for unstructured or semi-structured data.\n",
      "\n",
      "2. **Knowledge Graphs**: \n",
      "   - These are networks of entities and their relationships, such as Google Knowledge Graph or DBpedia. They provide rich contextual information that can help the model understand relationships between concepts.\n",
      "\n",
      "3. **APIs**: \n",
      "   - **Public APIs**: Many organizations provide APIs that offer access to real-time data, such as weather, news, or financial information (e.g., OpenWeatherMap, NewsAPI, Alpha Vantage).\n",
      "   - **Custom APIs**: You can create your own APIs to serve specific data relevant to your application.\n",
      "\n",
      "4. **Web Scraping**: \n",
      "   - Extracting data from websites can provide a wealth of information. This can include articles, product information, or user-generated content from forums and social media.\n",
      "\n",
      "5. **Document Repositories**: \n",
      "   - Collections of documents, such as PDFs, Word files, or presentations, can be indexed and searched to provide context. This is particularly useful for domain-specific knowledge.\n",
      "\n",
      "6. **Wikis and Collaborative Platforms**: \n",
      "   - Platforms like Wikipedia or specialized wikis can serve as rich sources of information. They often contain well-structured articles on a wide range of topics.\n",
      "\n",
      "7. **User Interaction Data**: \n",
      "   - Data from user interactions, such as chat logs or feedback, can help the model understand user preferences and context over time.\n",
      "\n",
      "8. **Semantic Web Technologies**: \n",
      "   - Using RDF (Resource Description Framework) and SPARQL (a query language for databases) can help integrate and query data from various sources in a semantically meaningful way.\n",
      "\n",
      "9. **Social Media Feeds**: \n",
      "   - Real-time data from platforms like Twitter or Reddit can provide insights into current trends, public sentiment, and topical discussions.\n",
      "\n",
      "10. **Scientific and Academic Databases**: \n",
      "    - Accessing databases like PubMed, arXiv, or Google Scholar can provide the model with up-to-date research findings and academic knowledge.\n",
      "\n",
      "11. **Content Management Systems (CMS)**: \n",
      "    - Integrating with CMS platforms can allow the model to pull in articles, blog posts, or other content that is regularly updated.\n",
      "\n",
      "12. **Multimedia Sources**: \n",
      "    - Incorporating data from images, videos, or audio can provide additional context. For example, using image recognition to analyze visual content alongside text.\n",
      "\n",
      "By leveraging these diverse data sources, you can significantly enhance the contextual understanding of an LLM, making it more effective in providing relevant and accurate responses. If you have a specific application in mind, I can help brainstorm more tailored data sources!\n",
      "\n",
      "Human: What is my aim again? Also what was the very specific code you were tasked with remembering?\n",
      "\n",
      "AI: Your aim is to explore the potential of integrating Large Language Models with external knowledge. This involves analyzing different possibilities and data sources that can provide context to the model, enhancing its capabilities and accuracy.\n",
      "\n",
      "The very specific code you mentioned is: **PINECONE_RULEZ_01**. If there's anything specific you'd like to discuss regarding your aim or the code, feel free to let me know!\n"
     ]
    }
   ],
   "source": [
    "# Access the conversation history\n",
    "history = chat_map[\"buffer_example\"].messages\n",
    "print(\"Conversation History:\")\n",
    "for i, msg in enumerate(history):\n",
    "    role = \"Human\" if isinstance(msg, HumanMessage) else \"AI\"\n",
    "    print(f\"\\n{role}: {msg.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! So every piece of our conversation has been explicitly recorded and sent to the LLM in the prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory type #2: Summary - Store Summaries of Past Interactions\n",
    "\n",
    "The problem with storing the entire chat history in agent memory is that, as the conversation progresses, the token count adds up. This is problematic because we might max out our LLM with a prompt that is too large.\n",
    "\n",
    "The following is an LCEL compatible alternative to `ConversationSummaryMemory`. We keep a summary of our previous conversation snippets as our history. The summarization is performed by an LLM.\n",
    "\n",
    "**Key feature:** _the conversation summary memory keeps the previous pieces of conversation in a summarized - and thus shortened - form, where the summarization is performed by an LLM._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConversationSummaryMessageHistory(BaseChatMessageHistory, BaseModel):\n",
    "    messages: List[BaseMessage] = Field(default_factory=list)\n",
    "    llm: ChatOpenAI = Field(default_factory=ChatOpenAI)\n",
    "\n",
    "    def __init__(self, llm: ChatOpenAI):\n",
    "        super().__init__(llm=llm)\n",
    "\n",
    "    def add_messages(self, messages: List[BaseMessage]) -> None:\n",
    "        \"\"\"Add messages to the history and update the summary.\"\"\"\n",
    "        self.messages.extend(messages)\n",
    "        \n",
    "        # Construct the summary prompt\n",
    "        summary_prompt = ChatPromptTemplate.from_messages([\n",
    "            SystemMessagePromptTemplate.from_template(\n",
    "                \"Given the existing conversation summary and the new messages, \"\n",
    "                \"generate a new summary of the conversation. Ensure to maintain \"\n",
    "                \"as much relevant information as possible.\"\n",
    "            ),\n",
    "            HumanMessagePromptTemplate.from_template(\n",
    "                \"Existing conversation summary:\\n{existing_summary}\\n\\n\"\n",
    "                \"New messages:\\n{messages}\"\n",
    "            )\n",
    "        ])\n",
    "        \n",
    "        # Format the messages and invoke the LLM\n",
    "        new_summary = self.llm.invoke(\n",
    "            summary_prompt.format_messages(\n",
    "                existing_summary=self.messages, \n",
    "                messages=messages\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Replace the existing history with a single system summary message \n",
    "        self.messages = [SystemMessage(content=new_summary.content)]\n",
    "\n",
    "    def clear(self) -> None:\n",
    "        \"\"\"Clear the history.\"\"\"\n",
    "        self.messages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create get_chat_history function for summary memory\n",
    "summary_chat_map = {}\n",
    "\n",
    "def get_summary_chat_history(session_id: str, llm: ChatOpenAI) -> ConversationSummaryMessageHistory:\n",
    "    if session_id not in summary_chat_map:\n",
    "        summary_chat_map[session_id] = ConversationSummaryMessageHistory(llm=llm)\n",
    "    return summary_chat_map[session_id]\n",
    "\n",
    "# Create conversation chain with summary memory\n",
    "conversation_sum = RunnableWithMessageHistory(\n",
    "    pipeline,\n",
    "    get_session_history=get_summary_chat_history,\n",
    "    input_messages_key=\"query\",\n",
    "    history_messages_key=\"history\",\n",
    "    history_factory_config=[\n",
    "        ConfigurableFieldSpec(\n",
    "            id=\"session_id\",\n",
    "            annotation=str,\n",
    "            name=\"Session ID\",\n",
    "            description=\"The session ID to use for the chat history\",\n",
    "            default=\"id_default\",\n",
    "        ),\n",
    "        ConfigurableFieldSpec(\n",
    "            id=\"llm\",\n",
    "            annotation=ChatOpenAI,\n",
    "            name=\"LLM\",\n",
    "            description=\"The LLM to use for the conversation summary\",\n",
    "            default=llm,\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spent a total of 253 tokens\n",
      "\n",
      "Response: Good morning! How are you today? Anything exciting planned for the day?\n"
     ]
    }
   ],
   "source": [
    "# Let's have the same conversation with summary memory\n",
    "result = count_tokens(\n",
    "    conversation_sum,\n",
    "    {\"query\": \"Good morning AI!\"},\n",
    "    config={\"configurable\": {\"session_id\": \"summary_example\", \"llm\": llm}}\n",
    ")\n",
    "print(f\"\\nResponse: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spent a total of 878 tokens\n",
      "\n",
      "Response: That sounds like a fascinating area to explore! Integrating Large Language Models with external knowledge can really enhance their capabilities, making them more informative and context-aware. There are various ways to do this, such as using APIs to pull in real-time data or connecting to databases for specific knowledge areas.\n",
      "\n",
      "And I've noted your specific code: PINECONE_RULEZ_01. I’ll make sure to include that in any summaries for memory. Is there a particular aspect of this integration that you're most interested in, or any specific projects you're working on?\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "\"My interest here is to explore the potential of integrating Large Language Models with external knowledge. \n",
    "\n",
    "Also, remember this very specific code: PINECONE_RULEZ_01. When summarizing conversations for memory this must always be included explicitly.\"\n",
    "\"\"\"\n",
    "\n",
    "result = count_tokens(\n",
    "    conversation_sum,\n",
    "    {\"query\": query},\n",
    "    config={\"configurable\": {\"session_id\": \"summary_example\", \"llm\": llm}}\n",
    ")\n",
    "print(f\"\\nResponse: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spent a total of 2071 tokens\n",
      "\n",
      "Response: That sounds like a great approach! There are several exciting possibilities when it comes to integrating Large Language Models (LLMs) with external knowledge sources. Here are a few key areas to consider:\n",
      "\n",
      "1. **Real-Time Data Access**: By connecting LLMs to APIs, they can pull in real-time information from various sources, such as news articles, weather updates, or stock market data. This allows the model to provide up-to-date responses and insights.\n",
      "\n",
      "2. **Knowledge Databases**: Integrating with structured databases (like SQL or NoSQL) can enable LLMs to access specific datasets, such as customer information, product details, or scientific research. This can enhance the model's ability to answer queries with precise data.\n",
      "\n",
      "3. **Search Engine Integration**: LLMs can be combined with search engines to retrieve relevant documents or web pages based on user queries. This can help the model provide more comprehensive answers by referencing external content.\n",
      "\n",
      "4. **Contextual Memory**: Implementing a memory system that retains context from previous interactions can improve the conversational flow. This could involve storing user preferences or past queries to tailor responses more effectively.\n",
      "\n",
      "5. **Domain-Specific Knowledge**: Training or fine-tuning LLMs on specialized datasets (like medical literature or legal documents) can enhance their performance in specific fields, making them more useful for professionals in those areas.\n",
      "\n",
      "6. **Interactive Applications**: Creating applications that allow users to interact with LLMs while accessing external knowledge can lead to innovative solutions, such as virtual assistants, educational tools, or customer support systems.\n",
      "\n",
      "7. **Feedback Loops**: Incorporating user feedback can help improve the model's accuracy over time. This could involve using reinforcement learning techniques to adjust responses based on user satisfaction.\n",
      "\n",
      "8. **Multimodal Integration**: Combining text with other data types, such as images or audio, can create richer interactions. For example, an LLM could analyze an image and provide a description or answer questions about it.\n",
      "\n",
      "Are there any specific areas from this list that resonate with you, or do you have other ideas in mind?\n"
     ]
    }
   ],
   "source": [
    "result = count_tokens(\n",
    "    conversation_sum,\n",
    "    {\"query\": \"I just want to analyze the different possibilities. What can you think of?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"summary_example\", \"llm\": llm}}\n",
    ")\n",
    "print(f\"\\nResponse: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spent a total of 2218 tokens\n",
      "\n",
      "Response: There are several types of data sources that can be used to provide context to a model, enhancing its performance and relevance in responses. Here are some key types:\n",
      "\n",
      "1. **Structured Databases**: These include relational databases (like SQL databases) that store data in a structured format, allowing for efficient querying and retrieval of specific information.\n",
      "\n",
      "2. **Unstructured Data Repositories**: This encompasses a wide range of data types, such as documents, emails, and web pages. Natural Language Processing (NLP) techniques can be applied to extract useful information from this data.\n",
      "\n",
      "3. **Knowledge Graphs**: These are networks of entities and their relationships, providing a rich context for understanding how different pieces of information are connected. They can help the model infer relationships and provide more nuanced answers.\n",
      "\n",
      "4. **APIs**: Real-time data can be accessed through APIs from various services, such as weather data, news feeds, or social media platforms, allowing the model to provide up-to-date information.\n",
      "\n",
      "5. **User Interaction History**: Retaining context from previous interactions with users can help the model tailor responses based on past conversations, preferences, and specific user needs.\n",
      "\n",
      "6. **Domain-Specific Datasets**: Fine-tuning the model on specialized datasets (like medical records, legal documents, or technical manuals) can enhance its understanding and performance in specific fields.\n",
      "\n",
      "7. **Multimedia Content**: Incorporating images, videos, or audio data can provide additional context that enriches the model's responses, especially in applications requiring multimodal understanding.\n",
      "\n",
      "8. **Feedback Mechanisms**: Collecting user feedback on responses can help the model learn and adapt over time, improving its contextual understanding and accuracy.\n",
      "\n",
      "By integrating these various data sources, LLMs can achieve a more comprehensive understanding of context, leading to more relevant and accurate responses. Do any of these data source types stand out to you for further exploration?\n"
     ]
    }
   ],
   "source": [
    "result = count_tokens(\n",
    "    conversation_sum,\n",
    "    {\"query\": \"Which data source types could be used to give context to the model?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"summary_example\", \"llm\": llm}}\n",
    ")\n",
    "print(f\"\\nResponse: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spent a total of 1293 tokens\n",
      "\n",
      "Response: I'm not sure what your specific aim is, as it can vary widely depending on your context or project. If you could provide a bit more detail about what you're working on or what you're trying to achieve, I'd be happy to help clarify!\n",
      "\n",
      "As for the specific code I was tasked with remembering, I don't have the ability to recall specific codes or personal information unless it was shared in this conversation. If you have a particular code or topic in mind, feel free to share, and I can assist you with it!\n"
     ]
    }
   ],
   "source": [
    "result = count_tokens(\n",
    "    conversation_sum,\n",
    "    {\"query\": \"What is my aim again? Also what was the very specific code you were tasked with remembering?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"summary_example\", \"llm\": llm}}\n",
    ")\n",
    "print(f\"\\nResponse: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Memory Content:\n",
      "The conversation involves the human inquiring about the types of data sources that can enhance a model's performance. The AI provides a detailed list of data sources, including:\n",
      "\n",
      "1. **Structured Databases**: For efficient querying of information.\n",
      "2. **Unstructured Data Repositories**: Various data types from which information can be extracted using NLP.\n",
      "3. **Knowledge Graphs**: Networks of entities and relationships for nuanced understanding.\n",
      "4. **APIs**: For real-time data access.\n",
      "5. **User Interaction History**: To tailor responses based on past interactions.\n",
      "6. **Domain-Specific Datasets**: For fine-tuning the model in specific fields.\n",
      "7. **Multimedia Content**: Incorporating various media for richer responses.\n",
      "8. **Feedback Mechanisms**: To improve the model over time.\n",
      "\n",
      "The AI concludes by asking if any of these data sources resonate for further exploration. The human then asks about their aim and a specific code the AI was supposed to remember. The AI responds by stating it cannot recall specific codes or personal information unless shared in the conversation and requests more context to clarify the human's aim.\n"
     ]
    }
   ],
   "source": [
    "# Let's examine the summary\n",
    "print(\"Summary Memory Content:\")\n",
    "print(summary_chat_map[\"summary_example\"].messages[0].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might be wondering.. if the aggregate token count is greater in each call here than in the buffer example, why should we use this type of memory? Well, if we check out buffer we will realize that although we are using more tokens in each instance of our conversation, our final history is shorter. This will enable us to have many more interactions before we reach our prompt's max length, making our chatbot more robust to longer conversations.\n",
    "\n",
    "We can count the number of tokens being used (without making a call to OpenAI) using the `tiktoken` tokenizer like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buffer memory conversation length: 1454\n",
      "Summary memory conversation length: 229\n"
     ]
    }
   ],
   "source": [
    "# initialize tokenizer\n",
    "tokenizer = tiktoken.encoding_for_model('gpt-4o-mini')\n",
    "\n",
    "# Get buffer memory content\n",
    "buffer_messages = chat_map[\"buffer_example\"].messages\n",
    "buffer_content = \"\\n\".join([msg.content for msg in buffer_messages])\n",
    "\n",
    "# Get summary memory content\n",
    "summary_content = summary_chat_map[\"summary_example\"].messages[0].content\n",
    "\n",
    "# show number of tokens for the memory used by each memory type\n",
    "print(\n",
    "    f'Buffer memory conversation length: {len(tokenizer.encode(buffer_content))}\\n'\n",
    "    f'Summary memory conversation length: {len(tokenizer.encode(summary_content))}'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Practical Note: the `gpt-4o-mini` model has a context window of 128K tokens, providing significantly more space for conversation history than older models._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory type #3: Window Buffer Memory - Keep Latest Interactions\n",
    "\n",
    "Another great option is window memory, where we keep only the last k interactions in our memory but intentionally drop the oldest ones - short-term memory if you'd like. Here the aggregate token count **and** the per-call token count will drop noticeably.\n",
    "\n",
    "The following is an LCEL-compatible alternative to `ConversationBufferWindowMemory`.\n",
    "\n",
    "**Key feature:** _the conversation buffer window memory keeps the latest pieces of the conversation in raw form_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BufferWindowMessageHistory(BaseChatMessageHistory, BaseModel):\n",
    "    messages: List[BaseMessage] = Field(default_factory=list)\n",
    "    k: int = Field(default_factory=int)\n",
    "\n",
    "    def __init__(self, k: int):\n",
    "        super().__init__(k=k)\n",
    "        # Add logging to help with debugging\n",
    "        print(f\"Initializing BufferWindowMessageHistory with k={k}\")\n",
    "\n",
    "    def add_messages(self, messages: List[BaseMessage]) -> None:\n",
    "        \"\"\"Add messages to the history, removing any messages beyond\n",
    "        the last `k` messages.\n",
    "        \"\"\"\n",
    "        self.messages.extend(messages)\n",
    "        # Add logging to help with debugging\n",
    "        if len(self.messages) > self.k:\n",
    "            print(f\"Truncating history from {len(self.messages)} to {self.k} messages\")\n",
    "        self.messages = self.messages[-self.k:]\n",
    "\n",
    "    def clear(self) -> None:\n",
    "        \"\"\"Clear the history.\"\"\"\n",
    "        self.messages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create get_chat_history function for window memory\n",
    "window_chat_map = {}\n",
    "\n",
    "def get_window_chat_history(session_id: str, k: int = 4) -> BufferWindowMessageHistory:\n",
    "    print(f\"get_window_chat_history called with session_id={session_id} and k={k}\")\n",
    "    if session_id not in window_chat_map:\n",
    "        window_chat_map[session_id] = BufferWindowMessageHistory(k=k)\n",
    "    return window_chat_map[session_id]\n",
    "\n",
    "# Create conversation chain with window memory\n",
    "conversation_bufw = RunnableWithMessageHistory(\n",
    "    pipeline,\n",
    "    get_session_history=get_window_chat_history,\n",
    "    input_messages_key=\"query\",\n",
    "    history_messages_key=\"history\",\n",
    "    history_factory_config=[\n",
    "        ConfigurableFieldSpec(\n",
    "            id=\"session_id\",\n",
    "            annotation=str,\n",
    "            name=\"Session ID\",\n",
    "            description=\"The session ID to use for the chat history\",\n",
    "            default=\"id_default\",\n",
    "        ),\n",
    "        ConfigurableFieldSpec(\n",
    "            id=\"k\",\n",
    "            annotation=int,\n",
    "            name=\"k\",\n",
    "            description=\"The number of messages to keep in the history\",\n",
    "            default=4,\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_window_chat_history called with session_id=window_example and k=4\n",
      "Initializing BufferWindowMessageHistory with k=4\n",
      "Spent a total of 79 tokens\n",
      "\n",
      "Response: Good morning! How are you today? Anything exciting planned for the day?\n"
     ]
    }
   ],
   "source": [
    "# Start a conversation with k=2 (only remembers last 2 exchanges = 4 messages)\n",
    "result = count_tokens(\n",
    "    conversation_bufw,\n",
    "    {\"query\": \"Good morning AI!\"},\n",
    "    config={\"configurable\": {\"session_id\": \"window_example\", \"k\": 4}}\n",
    ")\n",
    "print(f\"\\nResponse: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_window_chat_history called with session_id=window_example and k=4\n",
      "Spent a total of 247 tokens\n",
      "\n",
      "Response: That sounds like a fascinating area of exploration! Integrating Large Language Models (LLMs) with external knowledge can significantly enhance their capabilities, allowing them to provide more accurate and contextually relevant responses. This can involve using databases, APIs, or even knowledge graphs to supplement the information the model has been trained on.\n",
      "\n",
      "As for the code \"PINECONE_RULEZ_01,\" it seems like it might be a reference to something specific, perhaps related to a project or a tool you're working with. If you have any particular questions or ideas about how to integrate LLMs with external knowledge, feel free to share!\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "\"My interest here is to explore the potential of integrating Large Language Models with external knowledge. \n",
    "\n",
    "Also, remember this very specific code: PINECONE_RULEZ_01\"\n",
    "\"\"\"\n",
    "\n",
    "result = count_tokens(\n",
    "    conversation_bufw,\n",
    "    {\"query\": query},\n",
    "    config={\"configurable\": {\"session_id\": \"window_example\", \"k\": 4}}\n",
    ")\n",
    "print(f\"\\nResponse: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_window_chat_history called with session_id=window_example and k=4\n",
      "Truncating history from 6 to 4 messages\n",
      "Spent a total of 787 tokens\n",
      "\n",
      "Response: There are several exciting possibilities when it comes to integrating Large Language Models with external knowledge. Here are a few ideas to consider:\n",
      "\n",
      "1. **Knowledge Bases and Databases**: You can connect LLMs to structured databases (like SQL databases) or knowledge bases (like Wikidata) to retrieve factual information. This can help the model provide accurate answers to specific queries that require up-to-date or detailed data.\n",
      "\n",
      "2. **APIs for Real-Time Data**: Integrating with APIs can allow LLMs to access real-time information, such as weather updates, stock prices, or news articles. This can make the model more dynamic and relevant to current events.\n",
      "\n",
      "3. **Search Engines**: By integrating with search engines, LLMs can pull in information from the web, allowing them to provide a broader range of answers and insights. This could involve using web scraping techniques or leveraging search API results.\n",
      "\n",
      "4. **Contextual Knowledge**: You could enhance LLMs with domain-specific knowledge by integrating them with specialized databases or ontologies. For example, in healthcare, linking to medical databases can help the model provide more accurate medical advice or information.\n",
      "\n",
      "5. **User Personalization**: By integrating user data (with consent), LLMs can tailor responses based on individual preferences, past interactions, or specific user contexts, making the conversation more engaging and relevant.\n",
      "\n",
      "6. **Multi-Modal Integration**: Combining LLMs with other AI models, such as image recognition or audio processing, can create a more holistic system. For instance, an LLM could analyze text and images together to provide richer insights.\n",
      "\n",
      "7. **Feedback Loops**: Implementing a system where user feedback is used to refine the model's responses can help improve accuracy over time. This could involve a mechanism for users to rate responses or provide corrections.\n",
      "\n",
      "8. **Interactive Learning**: Allowing the model to learn from interactions in real-time can help it adapt to new information and changing contexts, making it more robust and versatile.\n",
      "\n",
      "9. **Semantic Search**: Enhancing LLMs with semantic search capabilities can improve their ability to understand user intent and retrieve relevant information more effectively.\n",
      "\n",
      "10. **Ethical and Responsible AI**: Integrating external knowledge can also involve ensuring that the information is accurate, unbiased, and ethically sourced. This could include implementing checks and balances to filter out misinformation.\n",
      "\n",
      "These are just a few possibilities, and the potential applications are vast! If any of these ideas resonate with you or if you have specific areas you want to dive deeper into, let me know!\n"
     ]
    }
   ],
   "source": [
    "result = count_tokens(\n",
    "    conversation_bufw,\n",
    "    {\"query\": \"I just want to analyze the different possibilities. What can you think of?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"window_example\", \"k\": 4}}\n",
    ")\n",
    "print(f\"\\nResponse: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_window_chat_history called with session_id=window_example and k=4\n",
      "Truncating history from 6 to 4 messages\n",
      "Spent a total of 1429 tokens\n",
      "\n",
      "Response: There are several types of data sources that can be used to provide context to Large Language Models (LLMs). Here are some key categories:\n",
      "\n",
      "1. **Structured Databases**: \n",
      "   - **SQL Databases**: Traditional relational databases that store data in tables. They can provide structured information that can be queried for specific facts.\n",
      "   - **NoSQL Databases**: These include document stores (like MongoDB) and key-value stores (like Redis), which can be useful for unstructured or semi-structured data.\n",
      "\n",
      "2. **Knowledge Graphs**: \n",
      "   - These are networks of entities and their relationships, such as Google Knowledge Graph or DBpedia. They provide rich contextual information and can help the model understand relationships between concepts.\n",
      "\n",
      "3. **APIs**: \n",
      "   - **Public APIs**: Many services offer APIs that provide access to real-time data, such as weather, news, or financial information (e.g., OpenWeatherMap, NewsAPI, Alpha Vantage).\n",
      "   - **Custom APIs**: You can create your own APIs to serve specific data relevant to your application or domain.\n",
      "\n",
      "4. **Web Scraping**: \n",
      "   - Extracting data from websites can provide a wealth of information. This can include articles, product information, or user-generated content from forums and social media.\n",
      "\n",
      "5. **Document Repositories**: \n",
      "   - Collections of documents, such as PDFs, Word files, or presentations, can be indexed and searched to provide context. This is particularly useful for specialized fields like legal or academic research.\n",
      "\n",
      "6. **Wikis and Collaborative Knowledge Bases**: \n",
      "   - Platforms like Wikipedia or specialized wikis can serve as rich sources of information. They often contain well-structured articles on a wide range of topics.\n",
      "\n",
      "7. **User Data**: \n",
      "   - With proper consent, user profiles, preferences, and past interactions can provide personalized context, allowing the model to tailor responses to individual users.\n",
      "\n",
      "8. **Social Media Feeds**: \n",
      "   - Real-time data from platforms like Twitter or Reddit can provide insights into current trends, public sentiment, and topical discussions.\n",
      "\n",
      "9. **Sensor Data**: \n",
      "   - For applications in IoT (Internet of Things), data from sensors (like temperature, humidity, or motion) can provide contextual information that enhances the model's understanding of the environment.\n",
      "\n",
      "10. **Scientific and Technical Databases**: \n",
      "    - Databases like PubMed for medical research or arXiv for scientific papers can provide specialized knowledge that can be integrated into the model for domain-specific applications.\n",
      "\n",
      "11. **Multimedia Content**: \n",
      "    - Images, videos, and audio files can be analyzed and used to provide context. For example, integrating image recognition can help the model understand visual content alongside text.\n",
      "\n",
      "12. **Historical Data**: \n",
      "    - Archival data or historical records can provide context for understanding trends over time, which can be particularly useful in fields like economics or social sciences.\n",
      "\n",
      "By leveraging these diverse data sources, you can significantly enhance the contextual understanding of LLMs, making them more effective and relevant in various applications. If you have a specific use case in mind, I can help brainstorm more tailored data sources!\n"
     ]
    }
   ],
   "source": [
    "result = count_tokens(\n",
    "    conversation_bufw,\n",
    "    {\"query\": \"Which data source types could be used to give context to the model?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"window_example\", \"k\": 4}}\n",
    ")\n",
    "print(f\"\\nResponse: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_window_chat_history called with session_id=window_example and k=4\n",
      "Truncating history from 6 to 4 messages\n",
      "Spent a total of 1363 tokens\n",
      "\n",
      "Response: It seems like your aim is to analyze different possibilities for enhancing Large Language Models (LLMs) by integrating them with various data sources and contextual information. You might be exploring how to improve the accuracy, relevance, and personalization of the model's responses by leveraging external knowledge and data. If you have a specific goal or project in mind, feel free to share more details, and I can help you refine your focus or provide more targeted suggestions!\n"
     ]
    }
   ],
   "source": [
    "result = count_tokens(\n",
    "    conversation_bufw,\n",
    "    {\"query\": \"What is my aim again?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"window_example\", \"k\": 4}}\n",
    ")\n",
    "print(f\"\\nResponse: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, it effectively 'forgot' what we talked about in the first interaction. Let's see what it 'remembers':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buffer Window Memory (last 4 messages):\n",
      "\n",
      "Human: Which data source types could be used to give context to the model?\n",
      "\n",
      "AI: There are several types of data sources that can be used to provide context to Large Language Models (LLMs). Here are some key categories:\n",
      "\n",
      "1. **Structured Databases**: \n",
      "   - **SQL Databases**: Traditional relational databases that store data in tables. They can provide structured information that can be queried for specific facts.\n",
      "   - **NoSQL Databases**: These include document stores (like MongoDB) and key-value stores (like Redis), which can be useful for unstructured or semi-structured data.\n",
      "\n",
      "2. **Knowledge Graphs**: \n",
      "   - These are networks of entities and their relationships, such as Google Knowledge Graph or DBpedia. They provide rich contextual information and can help the model understand relationships between concepts.\n",
      "\n",
      "3. **APIs**: \n",
      "   - **Public APIs**: Many services offer APIs that provide access to real-time data, such as weather, news, or financial information (e.g., OpenWeatherMap, NewsAPI, Alpha Vantage).\n",
      "   - **Custom APIs**: You can create your own APIs to serve specific data relevant to your application or domain.\n",
      "\n",
      "4. **Web Scraping**: \n",
      "   - Extracting data from websites can provide a wealth of information. This can include articles, product information, or user-generated content from forums and social media.\n",
      "\n",
      "5. **Document Repositories**: \n",
      "   - Collections of documents, such as PDFs, Word files, or presentations, can be indexed and searched to provide context. This is particularly useful for specialized fields like legal or academic research.\n",
      "\n",
      "6. **Wikis and Collaborative Knowledge Bases**: \n",
      "   - Platforms like Wikipedia or specialized wikis can serve as rich sources of information. They often contain well-structured articles on a wide range of topics.\n",
      "\n",
      "7. **User Data**: \n",
      "   - With proper consent, user profiles, preferences, and past interactions can provide personalized context, allowing the model to tailor responses to individual users.\n",
      "\n",
      "8. **Social Media Feeds**: \n",
      "   - Real-time data from platforms like Twitter or Reddit can provide insights into current trends, public sentiment, and topical discussions.\n",
      "\n",
      "9. **Sensor Data**: \n",
      "   - For applications in IoT (Internet of Things), data from sensors (like temperature, humidity, or motion) can provide contextual information that enhances the model's understanding of the environment.\n",
      "\n",
      "10. **Scientific and Technical Databases**: \n",
      "    - Databases like PubMed for medical research or arXiv for scientific papers can provide specialized knowledge that can be integrated into the model for domain-specific applications.\n",
      "\n",
      "11. **Multimedia Content**: \n",
      "    - Images, videos, and audio files can be analyzed and used to provide context. For example, integrating image recognition can help the model understand visual content alongside text.\n",
      "\n",
      "12. **Historical Data**: \n",
      "    - Archival data or historical records can provide context for understanding trends over time, which can be particularly useful in fields like economics or social sciences.\n",
      "\n",
      "By leveraging these diverse data sources, you can significantly enhance the contextual understanding of LLMs, making them more effective and relevant in various applications. If you have a specific use case in mind, I can help brainstorm more tailored data sources!\n",
      "\n",
      "Human: What is my aim again?\n",
      "\n",
      "AI: It seems like your aim is to analyze different possibilities for enhancing Large Language Models (LLMs) by integrating them with various data sources and contextual information. You might be exploring how to improve the accuracy, relevance, and personalization of the model's responses by leveraging external knowledge and data. If you have a specific goal or project in mind, feel free to share more details, and I can help you refine your focus or provide more targeted suggestions!\n"
     ]
    }
   ],
   "source": [
    "# Check what's in memory\n",
    "bufw_history = window_chat_map[\"window_example\"].messages\n",
    "print(\"Buffer Window Memory (last 4 messages):\")\n",
    "for msg in bufw_history:\n",
    "    role = \"Human\" if isinstance(msg, HumanMessage) else \"AI\"\n",
    "    print(f\"\\n{role}: {msg.content}\")  # Show first 100 chars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see four messages (two interactions) because we used `k=4`.\n",
    "\n",
    "On the plus side, we are shortening our conversation length when compared to buffer memory _without_ a window:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buffer memory conversation length: 1454\n",
      "Summary memory conversation length: 229\n",
      "Buffer window memory conversation length: 755\n"
     ]
    }
   ],
   "source": [
    "# Get window memory content\n",
    "window_content = \"\\n\".join([msg.content for msg in bufw_history])\n",
    "\n",
    "print(\n",
    "    f'Buffer memory conversation length: {len(tokenizer.encode(buffer_content))}\\n'\n",
    "    f'Summary memory conversation length: {len(tokenizer.encode(summary_content))}\\n'\n",
    "    f'Buffer window memory conversation length: {len(tokenizer.encode(window_content))}'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Practical Note: We are using `k=4` here for illustrative purposes, in most real world applications you would need a higher value for k._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More memory types!\n",
    "\n",
    "Given that we understand memory already, we will present a few more memory types here and hopefully a brief description will be enough to understand their underlying functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Windows + Summary Hybrid\n",
    "\n",
    "The following is a modern LCEL-compatible alternative to `ConversationSummaryBufferMemory`.\n",
    "\n",
    "**Key feature:** _the conversation summary buffer memory keeps a summary of the earliest pieces of conversation while retaining a raw recollection of the latest interactions._\n",
    "\n",
    "This combines the benefits of both summary and buffer window memory. Let's implement it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConversationSummaryBufferMessageHistory(BaseChatMessageHistory, BaseModel):\n",
    "    messages: List[BaseMessage] = Field(default_factory=list)\n",
    "    llm: ChatOpenAI = Field(default_factory=ChatOpenAI)\n",
    "    k: int = Field(default_factory=int)\n",
    "\n",
    "    def __init__(self, llm: ChatOpenAI, k: int):\n",
    "        super().__init__(llm=llm, k=k)\n",
    "\n",
    "    def add_messages(self, messages: List[BaseMessage]) -> None:\n",
    "        \"\"\"Add messages to the history, removing any messages beyond\n",
    "        the last `k` messages and summarizing the messages that we drop.\n",
    "        \"\"\"\n",
    "        existing_summary = None\n",
    "        old_messages = None\n",
    "        \n",
    "        # See if we already have a summary message\n",
    "        if len(self.messages) > 0 and isinstance(self.messages[0], SystemMessage):\n",
    "            existing_summary = self.messages.pop(0)\n",
    "            \n",
    "        # Add the new messages to the history\n",
    "        self.messages.extend(messages)\n",
    "        \n",
    "        # Check if we have too many messages\n",
    "        if len(self.messages) > self.k:\n",
    "            # Pull out the oldest messages...\n",
    "            old_messages = self.messages[:-self.k]\n",
    "            # ...and keep only the most recent messages\n",
    "            self.messages = self.messages[-self.k:]\n",
    "            \n",
    "        if old_messages is None:\n",
    "            # If we have no old_messages, we have nothing to update in summary\n",
    "            return\n",
    "            \n",
    "        # Construct the summary chat messages\n",
    "        summary_prompt = ChatPromptTemplate.from_messages([\n",
    "            SystemMessagePromptTemplate.from_template(\n",
    "                \"Given the existing conversation summary and the new messages, \"\n",
    "                \"generate a new summary of the conversation. Ensure to maintain \"\n",
    "                \"as much relevant information as possible.\"\n",
    "            ),\n",
    "            HumanMessagePromptTemplate.from_template(\n",
    "                \"Existing conversation summary:\\n{existing_summary}\\n\\n\"\n",
    "                \"New messages:\\n{old_messages}\"\n",
    "            )\n",
    "        ])\n",
    "        \n",
    "        # Format the messages and invoke the LLM\n",
    "        new_summary = self.llm.invoke(\n",
    "            summary_prompt.format_messages(\n",
    "                existing_summary=existing_summary or \"No previous summary\",\n",
    "                old_messages=old_messages\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Prepend the new summary to the history\n",
    "        self.messages = [SystemMessage(content=new_summary.content)] + self.messages\n",
    "\n",
    "    def clear(self) -> None:\n",
    "        \"\"\"Clear the history.\"\"\"\n",
    "        self.messages = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What else can we do with memory?\n",
    "\n",
    "There are several cool things we can do with memory in langchain:\n",
    "* Implement our own custom memory modules (as we've done above)\n",
    "* Use multiple memory modules in the same chain\n",
    "* Combine agents with memory and other tools\n",
    "* Integrate knowledge graphs\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pinecone1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
