{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TF8Js-1TEw22"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pinecone-io/examples/blob/master/generation/generative-qa/openai-ml-qa/00-build-index.ipynb) [![Open nbviewer](https://raw.githubusercontent.com/pinecone-io/examples/master/assets/nbviewer-shield.svg)](https://nbviewer.org/github/pinecone-io/examples/blob/master/generation/generative-qa/openai-ml-qa/00-build-index.ipynb)\n",
        "\n",
        "# Index Init\n",
        "\n",
        "We use this notebook to create embeddings with OpenAI and push the embeddings and metadata to Pinecone. Required installs for this notebook are:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0LDKVIxErRO",
        "outputId": "47a1a02b-a393-4b5e-8937-5334f59f0a27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/1.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.4/1.7 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qU openai tiktoken pinecone-client datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-WoLCa_E3Zm"
      },
      "source": [
        "## Data Preparation\n",
        "\n",
        "We start by downloading the dataset from Hugging Face *Datasets*:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LogOO33QE1Ic",
        "outputId": "f537c1a1-d259-4593-b31c-6d13841cfe49"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:datasets.builder:Found cached dataset json (/root/.cache/huggingface/datasets/jamescalam___json/jamescalam--ml-qa-2cecc52fb1e2761a/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['docs', 'category', 'thread', 'href', 'question', 'context', 'marked'],\n",
              "    num_rows: 6165\n",
              "})"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "data = load_dataset('jamescalam/ml-qa', split='train')\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ypJy8IEHGpU",
        "outputId": "59aea682-6107-4a23-992f-9ddf578b1eff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'docs': 'huggingface',\n",
              " 'category': 'Beginners',\n",
              " 'thread': 'Training stops when I try Fine-Tune XLSR-Wav2Vec2 for low-resource ASR',\n",
              " 'href': 'https://discuss.huggingface.co/t/training-stops-when-i-try-fine-tune-xlsr-wav2vec2-for-low-resource-asr/8981',\n",
              " 'question': 'Hi,\\nI‚Äôm learning Wav2Vec2 according the blog link:\\n  \\n\\n      huggingface.co\\n  \\n\\n  \\n    \\n\\nFine-Tune XLSR-Wav2Vec2 for low-resource ASR with ü§ó Transformers 1\\n\\n\\n\\n  \\n\\n  \\n    \\n    \\n  \\n\\n  \\n\\n\\nAnd I download the ipynb file and try run it locally.\\nFine_Tune_XLSR_Wav2Vec2_on_Turkish_ASR_with_ü§ó_Transformers.ipynb\\nAll looks file but when I run trainer.train(), it seems stop after a while, and it generate some log files under the folder wav2vec2-large-xlsr-turkish-demo, I send the screen shot to you as following:\\n\\n2021-08-05 17-05-36 ÁöÑÂ±èÂπïÊà™Âõæ1063√ó410 35 KB\\n\\nI don‚Äôt know how to open the file events.out.tfevents.1628152300.tq-sy.129248.2, what‚Äôs the problem and how can I debug of it? please help.\\nThanks a lot.',\n",
              " 'context': 'It probably stops cause u don‚Äôt have enough resources to run the script, I recommend trying to run the script on google collab',\n",
              " 'marked': 0}"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[100]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyo-aAcLFBvU"
      },
      "source": [
        "When storing the original plaintext (and other metadata) of our data, we can either store them in Pinecone as indexed or non-indexed metadata ‚Äî or elsewhere.\n",
        "\n",
        "Storing in Pinecone can make the system simpler as we are then querying a single location. However, there are limitations on metadata size. For *indexed* metadata this is 5KB of metadata, and for *non-indexed* metadata this is 40KB, [see here for more info](https://docs.pinecone.io/docs/limits#:~:text=Max%20metadata%20size%20per%20vector,key%20from%20the%20metadata%20payload.).\n",
        "\n",
        "First, let's check if we can fit our data within the larger 40KB limit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69PbCCSYE5qQ",
        "outputId": "073c77a5-f837-4a72-de09-e29d0358fc69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Over 40KB: 0.0%\n"
          ]
        }
      ],
      "source": [
        "from sys import getsizeof\n",
        "import json\n",
        "\n",
        "limit = 0\n",
        "\n",
        "for record in data:\n",
        "    size = getsizeof(json.dumps(record))\n",
        "    if size > 40_000:\n",
        "        limit += 1\n",
        "\n",
        "print(f\"Over 40KB: {(limit/len(data)*100)}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JccmDbwKV6L-"
      },
      "source": [
        "Fortunately our data is within this limit (40KB is a lot), so we don't need to remove anything to fit with Pinecone limits, but what about OpenAI limits?\n",
        "\n",
        "The current *token limit* for `text-embedding-ada-002` (the embedding model we will be using is **8191** tokens. However, later we will be using the `text-davinci-003` model for generation of answers, this model has a max context window of **~4K** tokens. We'll also want to feed in a few records here so we should limit ourselves to something closer to ~1000 tokens as a max limit.\n",
        "\n",
        "We calculate the number of tokens using the `tiktoken` tokenizer like so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wUwhYLSLv7o",
        "outputId": "e59c21cf-91a5-480f-aff1-b22bbccf1aec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Encoding 'p50k_base'>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tiktoken\n",
        "\n",
        "tokenizer = tiktoken.encoding_for_model('text-davinci-003')\n",
        "tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Giyv05G0NBll"
      },
      "source": [
        "Define token counting function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "p3DXr_5eNDSL"
      },
      "outputs": [],
      "source": [
        "# create the length function\n",
        "def tiktoken_len(text):\n",
        "    tokens = tokenizer.encode(\n",
        "        text,\n",
        "        disallowed_special=()\n",
        "    )\n",
        "    return len(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-MgipzZOAGR"
      },
      "source": [
        "Now let's filter out records that are longer than the ~2K."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106,
          "referenced_widgets": [
            "da7c88c7ee7042b3bea555cd83320609",
            "09fe265e5293459e90426de612d7f3b6",
            "73e0eda9407b4f638c143b408867fad9",
            "2d77ebf8177e49f995e8f1dd28a93de2",
            "79a5f690a1cf4112bd797eaf05891920",
            "07978e95c080400b85d80c100baa7592",
            "69c9b3c364484ff5a44cd4ebb686a7f7",
            "373a9a71c156478fa414f9fe358db496",
            "9888703f6a9f47fe92716e8ddad94870",
            "912637653f174b358b84e426e36b9cb4",
            "c0dd9468f41a47f99d89e033884040b2"
          ]
        },
        "id": "XtcM-rCQOJqH",
        "outputId": "d7f6d217-8df8-4c0e-a0ff-0fd8a35426f7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "da7c88c7ee7042b3bea555cd83320609",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Filter:   0%|          | 0/6165 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['docs', 'category', 'thread', 'href', 'question', 'context', 'marked'],\n",
              "    num_rows: 5947\n",
              "})"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = data.filter(\n",
        "    lambda x: 0 if tiktoken_len(\n",
        "      '\\n\\n'.join([x['thread'], x['question'], x['context']])\n",
        "    ) > 2_000 else 1\n",
        ")\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Allnxb0HLQlN"
      },
      "source": [
        "We've dropped ~200 rows. In a real-world scenario you may want to simply limit or chunk records, but for this example simply dropping the rows will do.\n",
        "\n",
        "Now let's move on to preparing the text data and building our embeddings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmhnlPckHrwF"
      },
      "source": [
        "## Text Prep and Embeddings\n",
        "\n",
        "To store as much information as possible in each record, it may make sense to format each record as something like:\n",
        "\n",
        "```\n",
        "Thread title: <thread>\n",
        "\n",
        "Question asked: <question>\n",
        "\n",
        "Given answer: <context>\n",
        "```\n",
        "\n",
        "We will create this format for each record and store in a new `text` variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WBvylTdHsOC",
        "outputId": "59bd3f27-264d-49ef-806b-d41c3ff005e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thread title: Extremely confusing or non-existent documentation about the Seq2Seq trainer\n",
            "\n",
            "Question asked: I‚Äôve been trying to train a model to translate database metadata + human requests into valid SQL.\n",
            "Initially, I used a wiki SQL base + a custom pytorch script (worked fine) but I decided I want to train my own from scratch and I‚Äôd better go with the ‚Äúmodern‚Äù method of using a trainer.\n",
            "The code I currently have is:\n",
            "        self.tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
            "        self.model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
            "        print('Creating datasets')\n",
            "        train_dataset = Dataset.from_dict({\n",
            "            'request': [x['prompt'] for x in data[:int(len(data) * 0.8)]],\n",
            "            'label': [x['completion'] for x in data[:int(len(data) * 0.8)]]\n",
            "        })\n",
            "        eval_dataset = Dataset.from_dict({\n",
            "            'request': [x['prompt'] for x in data[int(len(data) * 0.8):]],\n",
            "            'label': [x['completion'] for x in data[int(len(data) * 0.8):]]\n",
            "        })\n",
            "\n",
            "        print('Creating and starting trainer')\n",
            "        # Initialize our Trainer\n",
            "        trainer = Seq2SeqTrainer(\n",
            "            model=self.model,\n",
            "            train_dataset=train_dataset,\n",
            "            eval_dataset=eval_dataset,\n",
            "            tokenizer=self.tokenizer,\n",
            "            compute_metrics=self.compute_metrics,\n",
            "            args=Seq2SeqTrainingArguments(\n",
            "                output_dir='hft',\n",
            "                overwrite_output_dir=True,\n",
            "                do_train=True,\n",
            "                do_eval=True,\n",
            "                num_train_epochs=20,\n",
            "                generation_max_length=512,\n",
            "            )\n",
            "        )\n",
            "\n",
            "        trainer.evaluate()\n",
            "        trainer.train()\n",
            "        trainer.evaluate()\n",
            "\n",
            "Where the prompt and completion keys are both strings.\n",
            "This simply yileds the error:\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 20\n",
            "  Batch size = 8\n",
            "Traceback (most recent call last):\n",
            "  File \"itg/t5take5.py\", line 71, in <module>\n",
            "    t5t5.train(sparc_to_prompt())\n",
            "  File \"itg/t5take5.py\", line 59, in train\n",
            "    trainer.evaluate()\n",
            "  File \"/home/george/.local/lib/python3.8/site-packages/transformers/trainer_seq2seq.py\", line 70, in evaluate\n",
            "    return super().evaluate(eval_dataset, ignore_keys=ignore_keys, metric_key_prefix=metric_key_prefix)\n",
            "  File \"/home/george/.local/lib/python3.8/site-packages/transformers/trainer.py\", line 2151, in evaluate\n",
            "    output = eval_loop(\n",
            "  File \"/home/george/.local/lib/python3.8/site-packages/transformers/trainer.py\", line 2313, in evaluation_loop\n",
            "    for step, inputs in enumerate(dataloader):\n",
            "  File \"/home/george/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 521, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/home/george/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 561, in _next_data\n",
            "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
            "  File \"/home/george/.local/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n",
            "    return self.collate_fn(data)\n",
            "  File \"/home/george/.local/lib/python3.8/site-packages/transformers/data/data_collator.py\", line 246, in __call__\n",
            "    batch = self.tokenizer.pad(\n",
            "  File \"/home/george/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py\", line 2723, in pad\n",
            "    raise ValueError(\n",
            "ValueError: You should supply an encoding or a list of encodings to this method that includes input_ids, but you provided ['label']\n",
            "\n",
            "This is rather confusing, I‚Äôve tried renaming the label column to something else (SQL), this just results in training failing and evaluation doing nothing with the logs:\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 0\n",
            "  Batch size = 8\n",
            "The following columns in the training set  don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: request, SQL.\n",
            "\n",
            "I‚Äôve tried providing the label_names argument, but this is also useless and the same behavior manifests.\n",
            "Is the trainer‚Äôs documentation new?\n",
            "I also attempted looking at some examples, but the ‚Äúhard‚Äù part, that is to say, how do you actually get a dataset which is formatted in a valid way, is always missing.\n",
            "\n",
            "Given answer: Have you tried following the relevant course sections 6? (I linked to translation but summarization should be the same as well).\n",
            "Basically you are supplying raw datasets to the Seq2SeqTrainer and this can‚Äôt work, as it will need the inputs to the models (input_ids, labels, attention_mask etc.) so you need to tokenize your inputs and labels. This is all done in the examples you mention once you have your dataset with one column for the input texts and one column for the target texts.\n"
          ]
        }
      ],
      "source": [
        "text = [\n",
        "    f\"Thread title: {x['thread']}\\n\\n\"+\n",
        "    f\"Question asked: {x['question']}\\n\\n\"+\n",
        "    f\"Given answer: {x['context']}\" for x in data\n",
        "]\n",
        "print(text[100])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPf8HvEPMkky"
      },
      "source": [
        "The text isn't always going to be perfect, but we'll see that the embedding model doesn't have any issues with this. Now let's initialize the embedding model and begin building the embeddings.\n",
        "\n",
        "### Embedding with OpenAI\n",
        "\n",
        "We begin by initializing the embedding model. For this we need [OpenAI API keys](https://beta.openai.com/signup)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-Z653zZHBv6",
        "outputId": "ab6af831-094e-4d7d-9c39-81f219d646a5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<OpenAIObject list at 0x7f301b6ddf40> JSON: {\n",
              "  \"data\": [\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"babbage\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"davinci\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"text-davinci-edit-001\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"babbage-code-search-code\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-dev\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"text-similarity-babbage-001\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-dev\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"code-davinci-edit-001\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"text-davinci-001\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"ada\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"babbage-code-search-text\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-dev\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"babbage-similarity\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-dev\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"code-search-babbage-text-001\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-dev\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"text-curie-001\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"whisper-1\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-internal\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"code-search-babbage-code-001\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-dev\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"text-davinci-003\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-internal\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"text-ada-001\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"text-embedding-ada-002\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-internal\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"text-similarity-ada-001\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-dev\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"curie-instruct-beta\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"ada-code-search-code\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-dev\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"ada-similarity\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-dev\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"code-search-ada-text-001\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-dev\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"text-search-ada-query-001\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-dev\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"davinci-search-document\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-dev\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"ada-code-search-text\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-dev\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"text-search-ada-doc-001\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-dev\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"davinci-instruct-beta\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"text-similarity-curie-001\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-dev\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"code-search-ada-code-001\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-dev\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"ada-search-query\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-dev\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"text-search-davinci-query-001\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-dev\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"curie-search-query\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-dev\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"davinci-search-query\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-dev\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"babbage-search-document\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-dev\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"ada-search-document\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-dev\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"text-search-curie-query-001\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-dev\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"text-search-babbage-doc-001\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-dev\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"curie-search-document\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-dev\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"text-search-curie-doc-001\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-dev\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"babbage-search-query\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-dev\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"text-babbage-001\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"gpt-4\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"text-search-davinci-doc-001\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-dev\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"gpt-4-0314\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"text-search-babbage-query-001\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-dev\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"curie-similarity\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-dev\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"gpt-3.5-turbo-0301\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"curie\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"gpt-3.5-turbo\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"text-similarity-davinci-001\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-dev\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"text-davinci-002\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"davinci-similarity\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-dev\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    }\n",
              "  ],\n",
              "  \"object\": \"list\"\n",
              "}"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "# get API key from top-right dropdown on OpenAI website\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\") or \"OPENAI_API_KEY\"\n",
        "\n",
        "openai.Engine.list() # check we have authenticated"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9V0R8gAGOTSj"
      },
      "source": [
        "The `openai.Engine.list()` function should return a list of models that we can use. One of those is `text-embedding-ada-002` that we will use for creating embeddings like so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Ttkk5_GZOPt-"
      },
      "outputs": [],
      "source": [
        "model = \"text-embedding-ada-002\"\n",
        "\n",
        "res = openai.Embedding.create(\n",
        "    input=[\n",
        "        \"Sample document text goes here\",\n",
        "        \"there will be several phrases in each batch\"\n",
        "    ], engine=model\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XI2ObGnOqWC"
      },
      "source": [
        "In the response `res` we will find a JSON-like object containing our new embeddings within the `'data'` field."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNslbddQOzY0",
        "outputId": "3bd9c31b-a99a-4d6a-c056-0268636246d0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['object', 'data', 'model', 'usage'])"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "res.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aNIHsIYPTLm"
      },
      "source": [
        "Inside `'data'` we will find two records, one for each of the two sentences we just embedded. Each vector embedding contains `1536` dimensions (the output dimensionality of the `text-embedding-ada-002` model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDgPHDkyOqEz",
        "outputId": "747d3de2-8354-4c9c-fdbb-34ebe76155c3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(res['data'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrJ5Kq5tPSG0",
        "outputId": "c2a365bd-a036-4ed9-88d2-4c676fe561c0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1536, 1536)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(res['data'][0]['embedding']), len(res['data'][1]['embedding'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_Z2aoPoP14b"
      },
      "source": [
        "We will apply this same embedding logic when indexing all of our data in the Pinecone vector database soon.\n",
        "\n",
        "## Building a Pinecone Index\n",
        "\n",
        "We need a vector index to store the vector embeddings and enable a fast and scalable search through them. For this we use the Pinecone vector database.\n",
        "\n",
        "To use this we need a [free Pinecone API key](https://app.pinecone.io).\n",
        "\n",
        "Once ready, we initialize our index like so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "3NnNuDuDPhnV"
      },
      "outputs": [],
      "source": [
        "import pinecone\n",
        "\n",
        "index_name = 'openai-ml-qa'\n",
        "\n",
        "# initialize connection to pinecone (get API key at app.pinecone.io)\n",
        "pinecone.init(\n",
        "    api_key=\"PINECONE_API_KEY\",\n",
        "    environment=\"YOUR_ENV\"  # find next to API key in console\n",
        ")\n",
        "# check if 'openai-ml-qa' already exists (only create index if not)\n",
        "if index_name not in pinecone.list_indexes():\n",
        "    pinecone.create_index(\n",
        "        index_name,\n",
        "        dimension=len(res['data'][0]['embedding']),\n",
        "        metric='cosine',\n",
        "        # we may want to filter by docs (e.g. pytorch vs tensorflow)\n",
        "        metadata_config={'indexed': ['docs']}\n",
        "    )\n",
        "# connect to index\n",
        "index = pinecone.Index(index_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6JSgHpLRZ4B"
      },
      "source": [
        "We added `metadata_config={'indexed': ['docs']}` to fit anything that we don't plan on using as filterable fields in the *non-indexed* category. By doing this we optimize our index space, keeping the index more efficient.\n",
        "\n",
        "Now we begin populating the index.\n",
        "\n",
        "When adding records to Pinecone we need three items in a tuple format:\n",
        "\n",
        "```\n",
        "(id, vector, metadata)\n",
        "```\n",
        "\n",
        "All IDs must be unique, our vectors will be built by OpenAI, and the metadata is a dictionary of the information for each record (`'href'`, `'question'`, etc).\n",
        "\n",
        "We will create our vector embeddings and add the records to Pinecone in batches of `128`. This is to avoid trying to push too much data into single API requests."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "298a1b015dbe43f290ed2ddb87fc0057",
            "ff29c29abe3f41f18be00dc65c8e07ea",
            "2e923a912ef34272a36238383503b0a7",
            "d8db2d4a33504487968dca51eb59135a",
            "a6f2638e917841db82815fc0b6629ba8",
            "bb1f412a22a44842b48fb960b7c92a1c",
            "777fe865560a4a15a17672fddbb41b01",
            "fe264434a24143cf9cdb4322773249c0",
            "eb426bce7c77473892bde441cae0095e",
            "b202cb2c40484a42a4766a20ec94b1c2",
            "d0369655dcd544eb986c12e3fc6bd51f"
          ]
        },
        "id": "yVSn1lhFRp-R",
        "outputId": "8e44fae0-6fd8-4799-8134-3d3adc912cf1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "298a1b015dbe43f290ed2ddb87fc0057",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/47 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from tqdm.auto import tqdm  # this is our progress bar\n",
        "\n",
        "batch_size = 128  # process everything in batches of 128\n",
        "for i in tqdm(range(0, len(text), batch_size)):\n",
        "    # set end position of batch\n",
        "    i_end = min(i+batch_size, len(text))\n",
        "    # get batch of metadata, text, and IDs\n",
        "    meta_batch = [data[x] for x in range(i,i_end)]\n",
        "    text_batch = text[i:i_end]\n",
        "    ids_batch = [str(n) for n in range(i, i_end)]\n",
        "    # create embeddings\n",
        "    res = openai.Embedding.create(input=text_batch, engine=model)\n",
        "    embeds = [record['embedding'] for record in res['data']]\n",
        "    to_upsert = list(zip(ids_batch, embeds, meta_batch))\n",
        "    # upsert to Pinecone\n",
        "    index.upsert(vectors=to_upsert)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQXYWo_1btru"
      },
      "source": [
        "We can check that everything has been upserted with `index.describe_index_stats()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xhlc1hqLUW7f",
        "outputId": "42e0a279-8829-4d43-d16d-949f13178d49"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'dimension': 1536,\n",
              " 'index_fullness': 0.0,\n",
              " 'namespaces': {'': {'vector_count': 5947}},\n",
              " 'total_vector_count': 5947}"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "index.describe_index_stats()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4qKu3NNb2T0"
      },
      "source": [
        "We have `5947` vectors (and their respective metadata) added to the index as expected.\n",
        "\n",
        "With that our index has been built and we can move on to the next stage of querying in [01-making-queries.ipynb](https://github.com/pinecone-io/examples/blob/master/generation/generative-qa/openai-ml-qa/01-making-queries.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MpNGgCZVZt10"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.12 (main, Apr  5 2022, 01:52:34) \n[Clang 12.0.0 ]"
    },
    "vscode": {
      "interpreter": {
        "hash": "b8e7999f96e1b425e2d542f21b571f5a4be3e97158b0b46ea1b2500df63956ce"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "07978e95c080400b85d80c100baa7592": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09fe265e5293459e90426de612d7f3b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07978e95c080400b85d80c100baa7592",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_69c9b3c364484ff5a44cd4ebb686a7f7",
            "value": "Filter:  97%"
          }
        },
        "298a1b015dbe43f290ed2ddb87fc0057": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ff29c29abe3f41f18be00dc65c8e07ea",
              "IPY_MODEL_2e923a912ef34272a36238383503b0a7",
              "IPY_MODEL_d8db2d4a33504487968dca51eb59135a"
            ],
            "layout": "IPY_MODEL_a6f2638e917841db82815fc0b6629ba8"
          }
        },
        "2d77ebf8177e49f995e8f1dd28a93de2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_912637653f174b358b84e426e36b9cb4",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c0dd9468f41a47f99d89e033884040b2",
            "value": " 6000/6165 [00:02&lt;00:00, 2381.73 examples/s]"
          }
        },
        "2e923a912ef34272a36238383503b0a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe264434a24143cf9cdb4322773249c0",
            "max": 47,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eb426bce7c77473892bde441cae0095e",
            "value": 47
          }
        },
        "373a9a71c156478fa414f9fe358db496": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69c9b3c364484ff5a44cd4ebb686a7f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73e0eda9407b4f638c143b408867fad9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_373a9a71c156478fa414f9fe358db496",
            "max": 6165,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9888703f6a9f47fe92716e8ddad94870",
            "value": 6165
          }
        },
        "777fe865560a4a15a17672fddbb41b01": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79a5f690a1cf4112bd797eaf05891920": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "912637653f174b358b84e426e36b9cb4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9888703f6a9f47fe92716e8ddad94870": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a6f2638e917841db82815fc0b6629ba8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b202cb2c40484a42a4766a20ec94b1c2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb1f412a22a44842b48fb960b7c92a1c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0dd9468f41a47f99d89e033884040b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d0369655dcd544eb986c12e3fc6bd51f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8db2d4a33504487968dca51eb59135a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b202cb2c40484a42a4766a20ec94b1c2",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_d0369655dcd544eb986c12e3fc6bd51f",
            "value": " 47/47 [01:21&lt;00:00,  1.50s/it]"
          }
        },
        "da7c88c7ee7042b3bea555cd83320609": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_09fe265e5293459e90426de612d7f3b6",
              "IPY_MODEL_73e0eda9407b4f638c143b408867fad9",
              "IPY_MODEL_2d77ebf8177e49f995e8f1dd28a93de2"
            ],
            "layout": "IPY_MODEL_79a5f690a1cf4112bd797eaf05891920"
          }
        },
        "eb426bce7c77473892bde441cae0095e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fe264434a24143cf9cdb4322773249c0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff29c29abe3f41f18be00dc65c8e07ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb1f412a22a44842b48fb960b7c92a1c",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_777fe865560a4a15a17672fddbb41b01",
            "value": "100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
